{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.densenet import (\n",
    "    DenseNet121,\n",
    "    preprocess_input,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling2D,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "import efficientnet.tfkeras as enet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def append_extension(fn):\n",
    "    return (fn + \".jpg\").zfill(7)\n",
    "\n",
    "\n",
    "def ordered_logit(class_number):\n",
    "    # zero portability\n",
    "    target = np.zeros(4, dtype=int)\n",
    "    target[: class_number - 2] = 1\n",
    "    return target\n",
    "\n",
    "\n",
    "DATADIR = r\"./adult\"\n",
    "CSV_PATH = r\"./adult/CastControls_ALP.xlsx\"\n",
    "response = pd.read_excel(CSV_PATH, sheet_name=0,)[[\"GreenID\", \"Grade\"]].dropna(\n",
    "    axis=0, subset=[\"Grade\"]\n",
    ")\n",
    "response.Grade = response.Grade.astype(\"int\")\n",
    "response.GreenID = response.GreenID.astype(\"str\").apply(append_extension)\n",
    "response = response[response.Grade != 99]\n",
    "response = pd.concat(\n",
    "    [response, pd.DataFrame.from_dict(dict(response.Grade.apply(ordered_logit))).T,],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle dataset\n",
    "response = response.sample(frac=1)\n",
    "seed = np.random.randint(30027)\n",
    "\n",
    "\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "\n",
    "def soft_acc_multi_output(y_true, y_pred):\n",
    "    return K.mean(\n",
    "        K.all(\n",
    "            K.equal(\n",
    "                K.cast(K.round(y_true), \"int32\"), K.cast(K.round(y_pred), \"int32\"),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "# from tensorflow.keras import mixed_precision\n",
    "\n",
    "# policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "# mixed_precision.experimental.set_policy(policy)\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(\n",
    "            len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\",\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    fill_mode=\"reflect\",\n",
    "    horizontal_flip=True,\n",
    "    #     vertical_flip=True,\n",
    "    validation_split=0.1,\n",
    "    # dude i wasnt cheating...\n",
    "    rescale=1.0 / 255.0,\n",
    "    #     preprocessing_function = preprocess_input\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "valid_gen = ImageDataGenerator(validation_split=0.1, rescale=1.0 / 255.0,)\n",
    "\n",
    "train_set = train_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    #     class_mode = \"sparse\"\n",
    "    #     y_col=\"Grade\",\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "validation_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    batch_size=28,\n",
    "    #     class_mode = \"sparse\"\n",
    "    #     y_col=\"Grade\",\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "train_set.reset()\n",
    "validation_set.reset()\n",
    "# print(next(validation_set)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4e887602e298>:25: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 2 steps\n",
      "Epoch 1/25\n",
      "16/16 [==============================] - 11s 669ms/step - loss: 0.6069 - soft_acc_multi_output: 0.2124 - val_loss: 0.4696 - val_soft_acc_multi_output: 0.3571\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.4838 - soft_acc_multi_output: 0.3115 - val_loss: 0.3935 - val_soft_acc_multi_output: 0.4286\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 0.4403 - soft_acc_multi_output: 0.3268 - val_loss: 0.3645 - val_soft_acc_multi_output: 0.4643\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.4071 - soft_acc_multi_output: 0.3978 - val_loss: 0.3524 - val_soft_acc_multi_output: 0.4821\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.4045 - soft_acc_multi_output: 0.3818 - val_loss: 0.3363 - val_soft_acc_multi_output: 0.4821\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.3879 - soft_acc_multi_output: 0.3942 - val_loss: 0.3301 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 0.3993 - soft_acc_multi_output: 0.4017 - val_loss: 0.3252 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.3769 - soft_acc_multi_output: 0.4029 - val_loss: 0.3267 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.3710 - soft_acc_multi_output: 0.4532 - val_loss: 0.3134 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3648 - soft_acc_multi_output: 0.4408 - val_loss: 0.3185 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.3566 - soft_acc_multi_output: 0.4344 - val_loss: 0.3059 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3598 - soft_acc_multi_output: 0.4314 - val_loss: 0.3156 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 0.3551 - soft_acc_multi_output: 0.4807 - val_loss: 0.2991 - val_soft_acc_multi_output: 0.4821\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3533 - soft_acc_multi_output: 0.4884 - val_loss: 0.3131 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.3763 - soft_acc_multi_output: 0.4321 - val_loss: 0.2990 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.3663 - soft_acc_multi_output: 0.4442 - val_loss: 0.3008 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 5s 308ms/step - loss: 0.3455 - soft_acc_multi_output: 0.4797 - val_loss: 0.2985 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.3512 - soft_acc_multi_output: 0.4610 - val_loss: 0.2978 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.3634 - soft_acc_multi_output: 0.4452 - val_loss: 0.2891 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.3527 - soft_acc_multi_output: 0.4789 - val_loss: 0.3024 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.3424 - soft_acc_multi_output: 0.4962 - val_loss: 0.2897 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.3355 - soft_acc_multi_output: 0.5012 - val_loss: 0.3051 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.3406 - soft_acc_multi_output: 0.5098 - val_loss: 0.2981 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.3374 - soft_acc_multi_output: 0.4695 - val_loss: 0.2924 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 0.3361 - soft_acc_multi_output: 0.4848 - val_loss: 0.2859 - val_soft_acc_multi_output: 0.5357\n"
     ]
    }
   ],
   "source": [
    "conv_base = enet.EfficientNetB0(\n",
    "    include_top=False, input_shape=(224, 224, 3), pooling=\"avg\", weights=\"imagenet\",\n",
    ")\n",
    "conv_base.trainable = False\n",
    "\n",
    "x = conv_base.output\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(4, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=conv_base.input, outputs=preds)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[soft_acc_multi_output],\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "history_1 = model.fit_generator(\n",
    "    generator=train_set,\n",
    "    epochs=25,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau],\n",
    "    #     verbose=0,\n",
    ")\n",
    "\n",
    "# model.save(\n",
    "#     filepath=\"./saved_models/my_effnet/my_effnet_untuned_1_layer.h5\", save_format=\"h5\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 227 of 233 layers; 5 trainables variables\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 16 steps, validate for 2 steps\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 11s 679ms/step - loss: 0.5760 - soft_acc_multi_output: 0.3372 - val_loss: 0.3130 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.3600 - soft_acc_multi_output: 0.5082 - val_loss: 0.3111 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 0.3116 - soft_acc_multi_output: 0.5399 - val_loss: 0.3271 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.2968 - soft_acc_multi_output: 0.5624 - val_loss: 0.3075 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.2799 - soft_acc_multi_output: 0.5781 - val_loss: 0.3050 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 0.2575 - soft_acc_multi_output: 0.6148 - val_loss: 0.3134 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.2519 - soft_acc_multi_output: 0.6398 - val_loss: 0.3286 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 5s 314ms/step - loss: 0.2520 - soft_acc_multi_output: 0.6171 - val_loss: 0.2865 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 0.2293 - soft_acc_multi_output: 0.6464 - val_loss: 0.3166 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.2342 - soft_acc_multi_output: 0.6667 - val_loss: 0.3107 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.2185 - soft_acc_multi_output: 0.6832 - val_loss: 0.3253 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.2164 - soft_acc_multi_output: 0.6725 - val_loss: 0.3073 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 5s 314ms/step - loss: 0.2137 - soft_acc_multi_output: 0.6510 - val_loss: 0.3030 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.1913 - soft_acc_multi_output: 0.7256 - val_loss: 0.2914 - val_soft_acc_multi_output: 0.5893\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.1933 - soft_acc_multi_output: 0.7194 - val_loss: 0.3099 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.1885 - soft_acc_multi_output: 0.7373 - val_loss: 0.3176 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 0.1763 - soft_acc_multi_output: 0.7526 - val_loss: 0.3385 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.1832 - soft_acc_multi_output: 0.7404 - val_loss: 0.3142 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.1711 - soft_acc_multi_output: 0.7548 - val_loss: 0.3038 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 5s 303ms/step - loss: 0.1769 - soft_acc_multi_output: 0.7576 - val_loss: 0.3032 - val_soft_acc_multi_output: 0.5714\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 5s 307ms/step - loss: 0.1689 - soft_acc_multi_output: 0.7666 - val_loss: 0.3283 - val_soft_acc_multi_output: 0.5000\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.1587 - soft_acc_multi_output: 0.7915 - val_loss: 0.3187 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 5s 306ms/step - loss: 0.1620 - soft_acc_multi_output: 0.7771 - val_loss: 0.3148 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1691 - soft_acc_multi_output: 0.7670 - val_loss: 0.3413 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1517 - soft_acc_multi_output: 0.7951 - val_loss: 0.3551 - val_soft_acc_multi_output: 0.5357\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1471 - soft_acc_multi_output: 0.8075 - val_loss: 0.3255 - val_soft_acc_multi_output: 0.5179\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1593 - soft_acc_multi_output: 0.7873 - val_loss: 0.3340 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.1514 - soft_acc_multi_output: 0.7908 - val_loss: 0.3602 - val_soft_acc_multi_output: 0.5536\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 5s 309ms/step - loss: 0.1411 - soft_acc_multi_output: 0.8166 - val_loss: 0.3396 - val_soft_acc_multi_output: 0.5893\n"
     ]
    }
   ],
   "source": [
    "#########################\n",
    "## fine tuning\n",
    "#########################\n",
    "\n",
    "\n",
    "fine_tune = [layer.name for layer in model.layers].index(r\"top_conv\")\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:fine_tune]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[fine_tune:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "print(\n",
    "    f\"from {fine_tune} of {len(model.layers)} layers; {len(model.trainable_variables)} trainables variables\"\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[soft_acc_multi_output],\n",
    ")\n",
    "train_set.reset()\n",
    "validation_set.reset()\n",
    "\n",
    "\n",
    "# logdir_name = (\n",
    "#     r\".\\tfb\\logs\\effnet\\\\\"\n",
    "#     + \"effnet__1_layer\"\n",
    "#     + \"__\"\n",
    "#     + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# )\n",
    "# tensorboard_callback = TensorBoard(log_dir=logdir_name)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "# initial epoch is useless for keras optimizers as they update internally independent of epoch number\n",
    "history_fine = model.fit_generator(\n",
    "    generator=train_set,\n",
    "    epochs=100,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau,],\n",
    ")\n",
    "\n",
    "# model.save(\n",
    "#     filepath=\"./saved_models/my_effnet/tuned_1_layer.h5\", save_format=\"h5\",\n",
    "# )\n",
    "# model.save_weights(\n",
    "#     \"./saved_models/my_effnet/tuned_1_layer_weights_only.h5\", save_format=\"h5\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "# model__ = tf.keras.models.load_model(\n",
    "#     \"./saved_models/my_effnet/tuned_1_layer.h5\",\n",
    "#     custom_objects={\"soft_acc_multi_output\": soft_acc_multi_output},\n",
    "# )\n",
    "\n",
    "# model__.trainable = False\n",
    "# len(model__.trainable_variables)\n",
    "# model__.compile(\n",
    "#         optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         metrics=[soft_acc_multi_output],\n",
    "#     )\n",
    "\n",
    "model__ = generate_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 56 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "traintest = list(kf.split(np.zeros(len(response)), response[\"Grade\"]))\n",
    "train_index, test_index = np.stack(traintest)[:, 0][0], np.stack(traintest)[:, 1][0]\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    fill_mode=\"reflect\",\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0,\n",
    "    rescale=1.0 / 255.0,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "valid_gen = ImageDataGenerator(validation_split=0.5, rescale=1.0 / 255.0,)\n",
    "\n",
    "train_set = train_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[train_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=False,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "validation_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[test_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[test_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model__ = fine_tune_model(model__,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 647ms/step - loss: 0.8732 - soft_acc_multi_output: 0.1500 - val_loss: 0.4139 - val_soft_acc_multi_output: 0.3684\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.7882 - soft_acc_multi_output: 0.1792 - val_loss: 0.4187 - val_soft_acc_multi_output: 0.3509\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.6969 - soft_acc_multi_output: 0.1937 - val_loss: 0.4258 - val_soft_acc_multi_output: 0.4211\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.6181 - soft_acc_multi_output: 0.2625 - val_loss: 0.4342 - val_soft_acc_multi_output: 0.4035\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5712 - soft_acc_multi_output: 0.2750 - val_loss: 0.4419 - val_soft_acc_multi_output: 0.4737\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5283 - soft_acc_multi_output: 0.3583 - val_loss: 0.4488 - val_soft_acc_multi_output: 0.4912\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5110 - soft_acc_multi_output: 0.3562 - val_loss: 0.4532 - val_soft_acc_multi_output: 0.4912\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.4798 - soft_acc_multi_output: 0.4250 - val_loss: 0.4554 - val_soft_acc_multi_output: 0.4912\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.4474 - soft_acc_multi_output: 0.4250 - val_loss: 0.4571 - val_soft_acc_multi_output: 0.4912\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.4232 - soft_acc_multi_output: 0.4750 - val_loss: 0.4561 - val_soft_acc_multi_output: 0.4912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282fb52fa48>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch = next(test_set)\n",
    "# true_labels = batch[1]\n",
    "# predictions = model__.predict(batch[0])\n",
    "\n",
    "# print(model__.metrics_names)\n",
    "# print(\n",
    "#     model__.evaluate(train_set, verbose=0)\n",
    "# )  # working well with original unstratified model, including both trainning and testing sets?\n",
    "\n",
    "model__.fit(\n",
    "    x=train_set,\n",
    "    epochs=10,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau],\n",
    "    #         verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_base_model():\n",
    "    conv_base = enet.EfficientNetB0(\n",
    "        include_top=False, input_shape=(224, 224, 3), pooling=\"avg\", weights=\"imagenet\",\n",
    "    )\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    x = conv_base.output\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(\n",
    "        1,\n",
    "        activation=\"linear\",\n",
    "        bias_initializer=tf.keras.initializers.Constant(value=4),\n",
    "        bias_constraint=tf.keras.constraints.MinMaxNorm(\n",
    "            min_value=2, max_value=6, rate=1.0, axis=0\n",
    "        ),\n",
    "    )(x)\n",
    "    model = Model(inputs=conv_base.input, outputs=preds)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(lr=0.0014), loss=\"mse\", metrics=[soft_acc]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fine_tune_model(model, fine_tune=None):\n",
    "    if fine_tune is None:\n",
    "        try:\n",
    "            fine_tune = [layer.name for layer in model.layers].index(r\"top_conv\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    model.trainable = True\n",
    "    for layer in model.layers[:fine_tune]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[fine_tune:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(lr=0.0003), loss=\"mse\", metrics=[soft_acc],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def generate_train_val_test(train_index, val_index, test_index):\n",
    "    train_dataset = response.iloc[train_index]\n",
    "    val_dataset = response.iloc[val_index]\n",
    "    test_dataset = response.iloc[test_index]\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True,\n",
    "        rescale=1.0 / 255.0,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "    valid_test_gen = ImageDataGenerator(rescale=1.0 / 255.0,)\n",
    "\n",
    "    train_set = train_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True,\n",
    "        y_col=\"Grade\",\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    validation_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=val_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=\"Grade\",\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    test_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=\"Grade\",\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "innerkf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "response = response.sample(frac=1.0)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def stratified_cv(fine_tune_layer=None):\n",
    "    acc_coef_scores = []\n",
    "    raw_outputs = []\n",
    "    for train_index, val_test_index in kf.split(\n",
    "        np.zeros(len(response)), response[\"Grade\"]\n",
    "    ):\n",
    "        val_index, test_index = next(\n",
    "            innerkf.split(\n",
    "                np.zeros(len(val_test_index)), response[\"Grade\"].iloc[val_test_index]\n",
    "            )\n",
    "        )\n",
    "        val_index, test_index = val_test_index[val_index], val_test_index[test_index]\n",
    "        train_set, validation_set, test_set = generate_train_val_test(\n",
    "            train_index, val_index, test_index\n",
    "        )\n",
    "        model = generate_base_model()\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=15,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "                    verbose=0,\n",
    "        )\n",
    "\n",
    "        model = fine_tune_model(model, fine_tune=fine_tune_layer)\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=100,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "                    verbose=0,\n",
    "        )\n",
    "\n",
    "        batch = next(test_set)\n",
    "        true_labels = batch[1]\n",
    "        predictions = model.predict(batch[0])\n",
    "        acc = soft_acc_multi_output(predictions, true_labels).numpy()\n",
    "        corr = np.corrcoef(predictions.reshape(-1), true_labels)[0][1]\n",
    "        acc_coef_scores.append([acc, corr])\n",
    "        raw_outputs.append([np.array(response.iloc[test_index].index), true_labels, predictions.reshape(-1)])\n",
    "        del train_set, validation_set, test_set, _, model, batch, true_labels, predictions, acc, corr\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    return acc_coef_scores, raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  np.where(np.array(['conv' in layer.name for layer in model.layers]) == True)[0][::-1]\n",
    "from tqdm import tqdm\n",
    "\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "\n",
    "fine_tune_scores_acc_coef = []\n",
    "fine_tune_raw_outputs = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(28,30)):\n",
    "    fine_tune = trainable_sequence[i]\n",
    "    acc_coef_scores, raw_outputs = stratified_cv(fine_tune)\n",
    "    fine_tune_scores_acc_coef.append(acc_coef_scores)\n",
    "    fine_tune_raw_outputs.append(raw_outputs)\n",
    "    np.save(r\"./stratified_cross_validation_results/effnets/regression_acc_coef_28-30\", np.array(fine_tune_scores_acc_coef))\n",
    "    np.save(r\"./stratified_cross_validation_results/effnets/regression_raw_outputs_28-30\", np.array(fine_tune_raw_outputs))\n",
    "    del acc_coef_scores, raw_outputs\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[[29 13  1  0  0]\n",
      " [ 7 33 14  1  0]\n",
      " [ 4 26 36 11  1]\n",
      " [ 0  2 19 19 10]\n",
      " [ 0  0  6 24 27]]\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "[[0.6744186  0.30232558 0.02325581 0.         0.        ]\n",
      " [0.12727273 0.6        0.25454545 0.01818182 0.        ]\n",
      " [0.05128205 0.33333333 0.46153846 0.14102564 0.01282051]\n",
      " [0.         0.04       0.38       0.38       0.2       ]\n",
      " [0.         0.         0.10526316 0.42105263 0.47368421]]\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "Accuracy:  50.8833922261484\n",
      "Raw Correlation:  0.8286862054937622\n",
      "Rounded Correlation:  0.8145413736132224\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "max accuracy with tuning from 86 layers, or tune 147 layers\n",
      "[67.44186046511628, 60.0, 46.15384615384615, 38.0, 47.368421052631575]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_coef0 = np.load(\n",
    "    r\"./stratified_cross_validation_results/effnets/regression_acc_coef_0-20.npy\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "raw_outputs0 = np.load(\n",
    "    r\"./stratified_cross_validation_results/effnets/regression_raw_outputs_0-20.npy\",\n",
    "    allow_pickle=True,\n",
    ")\n",
    "acc_coef20 = np.load(r\"./stratified_cross_validation_results/effnets/regression_acc_coef_20-28.npy\", allow_pickle=True)\n",
    "raw_outputs20 = np.load(r\"./stratified_cross_validation_results/effnets/regression_raw_outputs_20-28.npy\", allow_pickle=True)\n",
    "acc_coef28 = np.load(r\"./stratified_cross_validation_results/effnets/regression_acc_coef_28-30.npy\", allow_pickle=True)\n",
    "raw_outputs28 = np.load(r\"./stratified_cross_validation_results/effnets/regression_raw_outputs_28-30.npy\", allow_pickle=True)\n",
    "acc_coef = np.vstack(np.array([acc_coef0,acc_coef20, acc_coef28]))\n",
    "raw_outputs = np.vstack(np.array([raw_outputs0,raw_outputs20, raw_outputs28]))\n",
    "\n",
    "\n",
    "print(len(acc_coef))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def show_confusion_matrix(raw_outputs, fine_tune_layers):\n",
    "\n",
    "    y_true = np.hstack(raw_outputs[fine_tune_layers, :, 1])\n",
    "    y_pred = np.rint(np.hstack(raw_outputs[fine_tune_layers, :, 2])).astype(\"int\")\n",
    "    y_pred[y_pred > 6] = 6\n",
    "    y_pred[y_pred < 2] = 2\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "\n",
    "def show_matrix_percentage(confusion_matrix):\n",
    "    return np.transpose(\n",
    "        np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1)\n",
    "    )\n",
    "\n",
    "\n",
    "# total accuracy\n",
    "def calculate_accuracy(my_confusion_matrix):\n",
    "    return np.trace(my_confusion_matrix) / np.sum(my_confusion_matrix)\n",
    "\n",
    "\n",
    "def raw_correlation(raw_outputs, fine_tune_layers):\n",
    "    y_true = np.hstack(raw_outputs[fine_tune_layers, :, 1]).astype(float)\n",
    "    y_pred = np.hstack(raw_outputs[fine_tune_layers, :, 2]).astype(float)\n",
    "    y_pred[y_pred > 6] = 6.0\n",
    "    y_pred[y_pred < 2] = 2.0\n",
    "    return np.corrcoef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def rounded_correlation(raw_outputs, fine_tune_layers):\n",
    "    y_true = np.hstack(raw_outputs[fine_tune_layers, :, 1]).astype(float)\n",
    "    y_pred = np.rint(np.hstack(raw_outputs[fine_tune_layers, :, 2])).astype(\"int\")\n",
    "    y_pred[y_pred > 6] = 6.0\n",
    "    y_pred[y_pred < 2] = 2.0\n",
    "    return np.corrcoef(y_true, y_pred)\n",
    "\n",
    "max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "\n",
    "my_confusion_matrix = show_confusion_matrix(raw_outputs, max_acc_layer)\n",
    "print(my_confusion_matrix)\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(show_matrix_percentage(my_confusion_matrix))\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"Accuracy: \",calculate_accuracy(my_confusion_matrix)*100)\n",
    "print(\"Raw Correlation: \",raw_correlation(raw_outputs,max_acc_layer)[0][1])\n",
    "print(\"Rounded Correlation: \",rounded_correlation(raw_outputs,max_acc_layer)[0][1])\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(\n",
    "    [i for i in range(len(acc_coef))],\n",
    "    [\n",
    "        calculate_accuracy(show_confusion_matrix(raw_outputs, i))\n",
    "        for i in range(len(acc_coef))\n",
    "    ],\n",
    ")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "print(f\"max accuracy with tuning from {trainable_sequence[max_acc_layer]} layers, or tune {233-trainable_sequence[max_acc_layer]} layers\")\n",
    "print([show_matrix_percentage(my_confusion_matrix)[i,i]*100 for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check 'cut places' with peaks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 112, 112, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 112, 112, 32) 128         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 112, 112, 32) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 112, 112, 32) 288         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 112, 112, 32) 128         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 112, 112, 32) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 32)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 32)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 8)      264         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 32)     288         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 112, 112, 32) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 112, 112, 16) 512         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 112, 112, 16) 64          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 112, 112, 96) 1536        block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 112, 112, 96) 384         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 112, 112, 96) 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 56, 56, 96)   864         block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 56, 56, 96)   384         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 56, 56, 96)   0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 96)           0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 96)     0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 4)      388         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 96)     480         block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 56, 56, 96)   0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 56, 56, 24)   2304        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 56, 56, 24)   96          block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 56, 56, 144)  576         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 56, 56, 144)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 56, 56, 144)  1296        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 56, 56, 144)  576         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 56, 56, 144)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 144)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 56, 56, 144)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 56, 56, 24)   3456        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 56, 56, 24)   96          block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 56, 56, 24)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 56, 56, 24)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 56, 56, 144)  3456        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 56, 56, 144)  576         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 56, 56, 144)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 28, 28, 144)  3600        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 28, 28, 144)  576         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 28, 28, 144)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 144)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 28, 28, 144)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 28, 28, 40)   5760        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 28, 28, 40)   160         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 28, 28, 240)  960         block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 28, 28, 240)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 28, 28, 240)  6000        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 28, 28, 240)  960         block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 28, 28, 240)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 240)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 240)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 28, 28, 240)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 28, 28, 40)   9600        block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 28, 28, 40)   160         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 28, 28, 40)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 28, 28, 40)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 28, 28, 240)  9600        block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 28, 28, 240)  960         block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 28, 28, 240)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 14, 14, 240)  2160        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 14, 14, 240)  960         block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 14, 14, 240)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 240)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 240)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 10)     2410        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 240)    2640        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 14, 14, 240)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 14, 14, 80)   19200       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 14, 14, 80)   320         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 14, 14, 480)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 14, 14, 480)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 480)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 14, 14, 480)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 14, 14, 80)   320         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 14, 14, 80)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 14, 14, 80)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 14, 14, 480)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 14, 14, 480)  4320        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 14, 14, 480)  1920        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 14, 14, 480)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 480)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 480)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 14, 14, 480)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 14, 14, 80)   38400       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 14, 14, 80)   320         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 14, 14, 80)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 14, 14, 80)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 14, 14, 480)  38400       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 14, 14, 480)  1920        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 14, 14, 480)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 14, 14, 480)  12000       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 14, 14, 480)  1920        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 14, 14, 480)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 480)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 480)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 20)     9620        block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 480)    10080       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 14, 14, 480)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 14, 14, 112)  53760       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 14, 14, 112)  448         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 14, 14, 672)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 14, 14, 672)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 672)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 14, 14, 672)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 14, 14, 112)  448         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 14, 14, 112)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 14, 14, 112)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 14, 14, 672)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 14, 14, 672)  16800       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 14, 14, 672)  2688        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 14, 14, 672)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 672)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 14, 14, 672)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 14, 14, 112)  75264       block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 14, 14, 112)  448         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 14, 14, 112)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 14, 14, 112)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 14, 14, 672)  75264       block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 14, 14, 672)  2688        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 14, 14, 672)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 7, 7, 672)    16800       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 7, 7, 672)    2688        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 7, 7, 672)    0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 672)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 7, 7, 672)    0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 7, 7, 192)    129024      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 7, 7, 192)    768         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 7, 7, 1152)   0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 7, 7, 1152)   0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1152)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 7, 7, 192)    768         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 7, 7, 192)    0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 7, 7, 192)    0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 7, 7, 1152)   0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 7, 7, 1152)   0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1152)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 7, 7, 192)    768         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 7, 7, 192)    0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 7, 7, 192)    0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 7, 7, 1152)   0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   28800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 7, 7, 1152)   0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1152)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 7, 7, 1152)   0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 7, 7, 192)    221184      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 7, 7, 192)    768         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 7, 7, 192)    0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 7, 7, 192)    0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 7, 7, 1152)   221184      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 7, 7, 1152)   4608        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 7, 7, 1152)   0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 7, 7, 1152)   10368       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 7, 7, 1152)   4608        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 7, 7, 1152)   0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1152)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1152)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 48)     55344       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1152)   56448       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 7, 7, 1152)   0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 7, 7, 320)    368640      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 7, 7, 320)    1280        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 7, 7, 1280)   409600      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 7, 7, 1280)   5120        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 7, 7, 1280)   0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1280)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1280)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1281        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,050,845\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 4,049,564\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_base_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cvscores)[:, 1][:, 0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54385966, 0.7954881615019466],\n",
       "       [0.5964912, 0.851205445137053],\n",
       "       [0.4107143, 0.7907964869050351],\n",
       "       [0.54545456, 0.8426871818521864],\n",
       "       [0.66071427, 0.8581865352844125]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cvscores)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  3,  1,  0,  0],\n",
       "       [ 0,  9,  3,  0,  0],\n",
       "       [ 1,  4, 11,  0,  0],\n",
       "       [ 0,  0,  3,  5,  3],\n",
       "       [ 0,  0,  1,  3,  5]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(\n",
    "    y_true=K.sum(K.cast(K.round(cvscores[1][1][0]), \"int32\"), axis=1).numpy(),\n",
    "    y_pred=K.sum(K.cast(K.round(cvscores[1][1][1]), \"int32\"), axis=1).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.DataFrame(\n",
    "    np.hstack(\n",
    "        np.array(\n",
    "            [\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 0]),\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 1]),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(mycsv[range(4, 8)].to_numpy(), np.vstack(np.array(cvscores)[:, 1][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv.to_csv(\n",
    "    \"./stratified_cross_validation_results/effnet_multinomial.csv\", index=False\n",
    ")\n",
    "# next time include which image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.read_csv(\"./stratified_cross_validation_results/effnet_multinomial.csv\")\n",
    "y_true = np.sum((mycsv[[str(i) for i in range(0, 4)]]).to_numpy(dtype=int), axis=1)\n",
    "y_pred = np.sum(\n",
    "    np.rint((mycsv[[str(i) for i in range(4, 8)]]).to_numpy()), axis=1\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[33, 10,  1,  0,  0],\n",
       "       [ 6, 36, 14,  1,  0],\n",
       "       [ 7, 22, 35,  5,  4],\n",
       "       [ 0,  2, 20, 17,  9],\n",
       "       [ 0,  0,  7, 17, 35]], dtype=int64)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "my_confusion_matrix = confusion_matrix(y_true, y_pred,)\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75      , 0.22727273, 0.02272727, 0.        , 0.        ],\n",
       "       [0.10526316, 0.63157895, 0.24561404, 0.01754386, 0.        ],\n",
       "       [0.09589041, 0.30136986, 0.47945205, 0.06849315, 0.05479452],\n",
       "       [0.        , 0.04166667, 0.41666667, 0.35416667, 0.1875    ],\n",
       "       [0.        , 0.        , 0.11864407, 0.28813559, 0.59322034]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.82710261],\n",
       "       [0.82710261, 1.        ]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coef\n",
    "np.corrcoef(y_true, np.sum((mycsv[[str(i) for i in range(4, 8)]]).to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5551601423487544"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acc\n",
    "sum(np.isclose(y_true, y_pred)) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, to_file=\"effnet.png\", show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "\n",
    "# Image(filename=\"effnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 281 validated image filenames.\n",
      "['loss', 'soft_acc_multi_output']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "[0.21299249678850174, 0.74404764]\n"
     ]
    }
   ],
   "source": [
    "response = response.sample(frac=1.0)\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    batch_size=56,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    "    #     seed = seed\n",
    ")\n",
    "\n",
    "batch = next(test_set)\n",
    "true_labels = batch[1]\n",
    "predictions = model.predict(batch[0])\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_set, verbose=0))  # loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.85824516],\n",
       "       [0.85824516, 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=80)\n",
    "batch = next(test_set)\n",
    "\n",
    "y_true = batch[1]\n",
    "y_pred = model.predict(batch[0])\n",
    "print(soft_acc_multi_output(y_true, y_pred))\n",
    "\n",
    "# print examples from the validation set\n",
    "for i in range(len(batch[1])):\n",
    "    img = batch[0][i]\n",
    "    label = batch[1][i]\n",
    "    assert (label == y_true[i]).all()\n",
    "    right = K.all(\n",
    "        K.equal(K.cast(K.round(label), \"int32\"), K.cast(K.round(y_pred[i]), \"int32\"),)\n",
    "    )\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(f\"true label: {label}; rounded pred: {y_pred[i]}; Correct: {right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(\n",
    "    str(\"C:/Users/feroc/OneDrive - The University of Melbourne/Dataset/adult/*\")\n",
    ")\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    image_id = tf.strings.split(file_path, os.path.sep)[-1]\n",
    "    return response.loc[] \n",
    "\n",
    "list(list_ds.take(1).as_numpy_iterator())[0]\n",
    "tf.strings.split(list(list_ds.take(1).as_numpy_iterator())[0],os.path.sep)[-1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
