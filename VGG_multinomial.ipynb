{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.densenet import (\n",
    "    DenseNet121,\n",
    "    preprocess_input,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling2D,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "import efficientnet.tfkeras as enet\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(\n",
    "            len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\",\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def append_extension(fn):\n",
    "    return (fn + \".jpg\").zfill(7)\n",
    "\n",
    "\n",
    "def ordered_logit(class_number):\n",
    "    # zero portability\n",
    "    target = np.zeros(4, dtype=int)\n",
    "    target[: class_number - 2] = 1\n",
    "    return target\n",
    "\n",
    "\n",
    "DATADIR = r\"./adult\"\n",
    "CSV_PATH = r\"./adult/CastControls_ALP.xlsx\"\n",
    "response = pd.read_excel(CSV_PATH, sheet_name=0,)[[\"GreenID\", \"Grade\"]].dropna(\n",
    "    axis=0, subset=[\"Grade\"]\n",
    ")\n",
    "response.Grade = response.Grade.astype(\"int\")\n",
    "response.GreenID = response.GreenID.astype(\"str\").apply(append_extension)\n",
    "response = response[response.Grade != 99]\n",
    "response = pd.concat(\n",
    "    [response, pd.DataFrame.from_dict(dict(response.Grade.apply(ordered_logit))).T,],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle dataset\n",
    "response = response.sample(frac=1)\n",
    "seed = np.random.randint(30027)\n",
    "\n",
    "\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "\n",
    "def soft_acc_multi_output(y_true, y_pred):\n",
    "    return K.mean(\n",
    "        K.all(\n",
    "            K.equal(\n",
    "                K.cast(K.round(y_true), \"int32\"), K.cast(K.round(y_pred), \"int32\"),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(train_index, val_index, test_index):\n",
    "    train_dataset = response.iloc[train_index]\n",
    "    val_dataset = response.iloc[val_index]\n",
    "    test_dataset = response.iloc[test_index]\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True,\n",
    "        rescale=1.0 / 255.0,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "    valid_test_gen = ImageDataGenerator(rescale=1.0 / 255.0,)\n",
    "\n",
    "    train_set = train_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    validation_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=val_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    test_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "innerkf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "response = response.sample(frac=1.0)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "\n",
    "def generate_base_model(fine_tune=None):\n",
    "    i = tf.keras.layers.Input([224, 224, 3], dtype = tf.uint8)\n",
    "    x = tf.cast(i, tf.float32)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "    conv_base = tf.keras.applications.VGG16(\n",
    "    include_top=False, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=\"avg\", classes=5,)\n",
    "    conv_base.trainable = True\n",
    "    x = conv_base(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(4, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=i, outputs=preds)\n",
    "                                                     \n",
    "    model.trainable = True\n",
    "#     for layer in model.layers[:fine_tune]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in model.layers[fine_tune:]:\n",
    "#         layer.trainable = True\n",
    "                                                     \n",
    "                                                     \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[soft_acc_multi_output],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def stratified_cv(fine_tune_layer=None):\n",
    "    acc_coef_scores = []\n",
    "    raw_outputs = []\n",
    "    for train_index, val_test_index in kf.split(\n",
    "        np.zeros(len(response)), response[\"Grade\"]\n",
    "    ):\n",
    "        val_index, test_index = next(\n",
    "            innerkf.split(\n",
    "                np.zeros(len(val_test_index)), response[\"Grade\"].iloc[val_test_index]\n",
    "            )\n",
    "        )\n",
    "        val_index, test_index = val_test_index[val_index], val_test_index[test_index]\n",
    "        train_set, validation_set, test_set = generate_train_val_test(\n",
    "            train_index, val_index, test_index\n",
    "        )\n",
    "        model = generate_base_model()\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=100,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "#             verbose=0,\n",
    "        )\n",
    "\n",
    "        batch = next(test_set)\n",
    "        true_labels = batch[1]\n",
    "        predictions = model.predict(batch[0])\n",
    "        acc = soft_acc_multi_output(predictions, true_labels).numpy()\n",
    "        corr = np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))[0][\n",
    "            1\n",
    "        ]\n",
    "        acc_coef_scores.append([acc, corr])\n",
    "        raw_outputs.append([np.array(response.iloc[test_index].index), true_labels, predictions])\n",
    "        del train_set, validation_set, test_set, _, model, batch, true_labels, predictions, acc, corr\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    return acc_coef_scores, raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 490ms/step - loss: 1.8791 - soft_acc_multi_output: 0.1021 - val_loss: 0.7271 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.9990 - soft_acc_multi_output: 0.1660 - val_loss: 0.6499 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.6866 - soft_acc_multi_output: 0.1625 - val_loss: 0.6118 - val_soft_acc_multi_output: 0.1636\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 1.1047 - soft_acc_multi_output: 0.1806 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.6586 - soft_acc_multi_output: 0.1847 - val_loss: 0.5654 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.6821 - soft_acc_multi_output: 0.2326 - val_loss: 0.5640 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.7274 - soft_acc_multi_output: 0.2493 - val_loss: 0.5630 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.6070 - soft_acc_multi_output: 0.2208 - val_loss: 0.5742 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5790 - soft_acc_multi_output: 0.2597 - val_loss: 0.5625 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5806 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5750 - soft_acc_multi_output: 0.2868 - val_loss: 0.5640 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5730 - soft_acc_multi_output: 0.2764 - val_loss: 0.5625 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5700 - soft_acc_multi_output: 0.2806 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5802 - soft_acc_multi_output: 0.2764 - val_loss: 0.5630 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5767 - soft_acc_multi_output: 0.2806 - val_loss: 0.5625 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5725 - soft_acc_multi_output: 0.2806 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5735 - soft_acc_multi_output: 0.2785 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5680 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5729 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5668 - soft_acc_multi_output: 0.2847 - val_loss: 0.5635 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5792 - soft_acc_multi_output: 0.2847 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5776 - soft_acc_multi_output: 0.2826 - val_loss: 0.5654 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5712 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5713 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5715 - soft_acc_multi_output: 0.2847 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5737 - soft_acc_multi_output: 0.2847 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5718 - soft_acc_multi_output: 0.2847 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5741 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5663 - soft_acc_multi_output: 0.2868 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5674 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5687 - soft_acc_multi_output: 0.2806 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5705 - soft_acc_multi_output: 0.2806 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5633 - soft_acc_multi_output: 0.2868 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5718 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5689 - soft_acc_multi_output: 0.2806 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5703 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5689 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5662 - soft_acc_multi_output: 0.2868 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5713 - soft_acc_multi_output: 0.2785 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.5781 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5710 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.5712 - soft_acc_multi_output: 0.2826 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5687 - soft_acc_multi_output: 0.2806 - val_loss: 0.5620 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5686 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5704 - soft_acc_multi_output: 0.2826 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 480ms/step - loss: 2.8466 - soft_acc_multi_output: 0.1417 - val_loss: 1.2002 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 1.2094 - soft_acc_multi_output: 0.1750 - val_loss: 0.5698 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.6335 - soft_acc_multi_output: 0.2396 - val_loss: 0.5747 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5750 - soft_acc_multi_output: 0.2521 - val_loss: 0.5684 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5759 - soft_acc_multi_output: 0.2125 - val_loss: 0.5684 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5884 - soft_acc_multi_output: 0.2625 - val_loss: 0.5708 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5801 - soft_acc_multi_output: 0.2229 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 303ms/step - loss: 0.5692 - soft_acc_multi_output: 0.2604 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5609 - soft_acc_multi_output: 0.2542 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5648 - soft_acc_multi_output: 0.2604 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5674 - soft_acc_multi_output: 0.2812 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5697 - soft_acc_multi_output: 0.2521 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 300ms/step - loss: 0.5656 - soft_acc_multi_output: 0.2708 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5629 - soft_acc_multi_output: 0.2604 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5667 - soft_acc_multi_output: 0.2646 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.5586 - soft_acc_multi_output: 0.2688 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5589 - soft_acc_multi_output: 0.2646 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5605 - soft_acc_multi_output: 0.2583 - val_loss: 0.5688 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5589 - soft_acc_multi_output: 0.2979 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5591 - soft_acc_multi_output: 0.2604 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5652 - soft_acc_multi_output: 0.2542 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5596 - soft_acc_multi_output: 0.2625 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.5600 - soft_acc_multi_output: 0.2604 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5627 - soft_acc_multi_output: 0.2479 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5631 - soft_acc_multi_output: 0.2625 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.5609 - soft_acc_multi_output: 0.2625 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5621 - soft_acc_multi_output: 0.2625 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5592 - soft_acc_multi_output: 0.2625 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5577 - soft_acc_multi_output: 0.2625 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5576 - soft_acc_multi_output: 0.2604 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5613 - soft_acc_multi_output: 0.2604 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5592 - soft_acc_multi_output: 0.2625 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5578 - soft_acc_multi_output: 0.2604 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5645 - soft_acc_multi_output: 0.2583 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5527 - soft_acc_multi_output: 0.2583 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 451ms/step - loss: 1.3088 - soft_acc_multi_output: 0.1562 - val_loss: 0.5654 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.8117 - soft_acc_multi_output: 0.1583 - val_loss: 0.5698 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.7227 - soft_acc_multi_output: 0.1896 - val_loss: 0.6221 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.6383 - soft_acc_multi_output: 0.1917 - val_loss: 0.5605 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.6774 - soft_acc_multi_output: 0.2708 - val_loss: 0.5625 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.6632 - soft_acc_multi_output: 0.2125 - val_loss: 0.5649 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.6181 - soft_acc_multi_output: 0.2271 - val_loss: 0.5576 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5832 - soft_acc_multi_output: 0.2604 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 300ms/step - loss: 0.5779 - soft_acc_multi_output: 0.2792 - val_loss: 0.5537 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5739 - soft_acc_multi_output: 0.2958 - val_loss: 0.5601 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5769 - soft_acc_multi_output: 0.2896 - val_loss: 0.5552 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5680 - soft_acc_multi_output: 0.2896 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5712 - soft_acc_multi_output: 0.2896 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.5829 - soft_acc_multi_output: 0.2875 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5677 - soft_acc_multi_output: 0.2896 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5663 - soft_acc_multi_output: 0.2917 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5601 - soft_acc_multi_output: 0.2875 - val_loss: 0.5557 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5733 - soft_acc_multi_output: 0.2854 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5683 - soft_acc_multi_output: 0.2917 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 4s 285ms/step - loss: 0.5706 - soft_acc_multi_output: 0.2917 - val_loss: 0.5557 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5679 - soft_acc_multi_output: 0.2917 - val_loss: 0.5557 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5686 - soft_acc_multi_output: 0.2917 - val_loss: 0.5576 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5663 - soft_acc_multi_output: 0.2917 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5641 - soft_acc_multi_output: 0.2896 - val_loss: 0.5557 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5679 - soft_acc_multi_output: 0.2896 - val_loss: 0.5552 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5647 - soft_acc_multi_output: 0.2917 - val_loss: 0.5552 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 4s 285ms/step - loss: 0.5709 - soft_acc_multi_output: 0.2917 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5678 - soft_acc_multi_output: 0.2917 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5617 - soft_acc_multi_output: 0.2896 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5668 - soft_acc_multi_output: 0.2896 - val_loss: 0.5552 - val_soft_acc_multi_output: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 434ms/step - loss: 1.8793 - soft_acc_multi_output: 0.1063 - val_loss: 0.6929 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 1.1357 - soft_acc_multi_output: 0.1312 - val_loss: 0.6338 - val_soft_acc_multi_output: 0.1607\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 300ms/step - loss: 0.8888 - soft_acc_multi_output: 0.1396 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.1607\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.7624 - soft_acc_multi_output: 0.1833 - val_loss: 0.5737 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.6221 - soft_acc_multi_output: 0.2292 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.6277 - soft_acc_multi_output: 0.2146 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5980 - soft_acc_multi_output: 0.2271 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 300ms/step - loss: 0.5698 - soft_acc_multi_output: 0.2438 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 286ms/step - loss: 0.5811 - soft_acc_multi_output: 0.2438 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5802 - soft_acc_multi_output: 0.2500 - val_loss: 0.5610 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5760 - soft_acc_multi_output: 0.2542 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5798 - soft_acc_multi_output: 0.2583 - val_loss: 0.5635 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5758 - soft_acc_multi_output: 0.2479 - val_loss: 0.5615 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5768 - soft_acc_multi_output: 0.2583 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5696 - soft_acc_multi_output: 0.2646 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5696 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5706 - soft_acc_multi_output: 0.2604 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 4s 294ms/step - loss: 0.5658 - soft_acc_multi_output: 0.2500 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5771 - soft_acc_multi_output: 0.2583 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5689 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5731 - soft_acc_multi_output: 0.2542 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5747 - soft_acc_multi_output: 0.2562 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5648 - soft_acc_multi_output: 0.2604 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5686 - soft_acc_multi_output: 0.2562 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5703 - soft_acc_multi_output: 0.2604 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5694 - soft_acc_multi_output: 0.2604 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5755 - soft_acc_multi_output: 0.2625 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5693 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5717 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 451 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 439ms/step - loss: 4.7635 - soft_acc_multi_output: 0.1417 - val_loss: 0.7847 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 1.0134 - soft_acc_multi_output: 0.2139 - val_loss: 0.6431 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 4s 299ms/step - loss: 0.5993 - soft_acc_multi_output: 0.2694 - val_loss: 0.5708 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.7010 - soft_acc_multi_output: 0.2632 - val_loss: 0.5815 - val_soft_acc_multi_output: 0.1818\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.5989 - soft_acc_multi_output: 0.2139 - val_loss: 0.5625 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5804 - soft_acc_multi_output: 0.2431 - val_loss: 0.5630 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5763 - soft_acc_multi_output: 0.2472 - val_loss: 0.5571 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5713 - soft_acc_multi_output: 0.2722 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5624 - soft_acc_multi_output: 0.2639 - val_loss: 0.5576 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 4s 297ms/step - loss: 0.5680 - soft_acc_multi_output: 0.2785 - val_loss: 0.5693 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.7597 - soft_acc_multi_output: 0.2333 - val_loss: 0.6108 - val_soft_acc_multi_output: 0.1818\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 1.0193 - soft_acc_multi_output: 0.1917 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.6147 - soft_acc_multi_output: 0.2722 - val_loss: 0.5854 - val_soft_acc_multi_output: 0.2000\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 1.2482 - soft_acc_multi_output: 0.2035 - val_loss: 0.5981 - val_soft_acc_multi_output: 0.1818\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5976 - soft_acc_multi_output: 0.2285 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5650 - soft_acc_multi_output: 0.2951 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 4s 295ms/step - loss: 0.5651 - soft_acc_multi_output: 0.3069 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5663 - soft_acc_multi_output: 0.2826 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5686 - soft_acc_multi_output: 0.2764 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 4s 291ms/step - loss: 0.5655 - soft_acc_multi_output: 0.2785 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 4s 293ms/step - loss: 0.5611 - soft_acc_multi_output: 0.2847 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 4s 292ms/step - loss: 0.5535 - soft_acc_multi_output: 0.2806 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 4s 298ms/step - loss: 0.5611 - soft_acc_multi_output: 0.2826 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5603 - soft_acc_multi_output: 0.2764 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5583 - soft_acc_multi_output: 0.2847 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5571 - soft_acc_multi_output: 0.2826 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5565 - soft_acc_multi_output: 0.2785 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 4s 296ms/step - loss: 0.5612 - soft_acc_multi_output: 0.2868 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5590 - soft_acc_multi_output: 0.2785 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5570 - soft_acc_multi_output: 0.2806 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5614 - soft_acc_multi_output: 0.2826 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5532 - soft_acc_multi_output: 0.2847 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 4s 289ms/step - loss: 0.5567 - soft_acc_multi_output: 0.2826 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5582 - soft_acc_multi_output: 0.2806 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 4s 290ms/step - loss: 0.5563 - soft_acc_multi_output: 0.2826 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5550 - soft_acc_multi_output: 0.2806 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 4s 288ms/step - loss: 0.5584 - soft_acc_multi_output: 0.2826 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.2727\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 4s 287ms/step - loss: 0.5572 - soft_acc_multi_output: 0.2806 - val_loss: 0.5562 - val_soft_acc_multi_output: 0.2727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fine_tune_scores_acc_coef' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-f86844340ad4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0macc_coef_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstratified_cv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfine_tune_scores_acc_coef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc_coef_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fine_tune_scores_acc_coef' is not defined"
     ]
    }
   ],
   "source": [
    "acc_coef_scores, raw_outputs = stratified_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe also include an untuned version for comparison?\n",
    "# np.array([list(response.iloc[np.stack(np.array(raw_outputs)[0,:,0])[i]].index) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_coef = []\n",
    "raw_outputs = []\n",
    "acc_coef.append(acc_coef_scores)\n",
    "raw_outputs.append(raw_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1dc426617deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mmy_confusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_confusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"+++++++++++++++++++++++++++++++++\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-1dc426617deb>\u001b[0m in \u001b[0;36mshow_confusion_matrix\u001b[1;34m(raw_outputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     y_pred = np.sum(\n\u001b[0;32m     13\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(len(acc_coef))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def show_confusion_matrix(raw_outputs):\n",
    "\n",
    "    y_true = np.sum(raw_outputs[:, 1], axis=1)\n",
    "    y_pred = np.sum(\n",
    "        np.rint(raw_outputs[:, 2]), axis=1\n",
    "    ).astype(int)\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def show_matrix_percentage(confusion_matrix):\n",
    "    return np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))\n",
    "\n",
    "# total accuracy\n",
    "def calculate_accuracy(my_confusion_matrix):\n",
    "    return np.trace(my_confusion_matrix)/np.sum(my_confusion_matrix)\n",
    "\n",
    "# max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "\n",
    "my_confusion_matrix = show_confusion_matrix(raw_outputs)\n",
    "print(my_confusion_matrix)\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(show_matrix_percentage(my_confusion_matrix))\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(calculate_accuracy(my_confusion_matrix)*100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(len(acc_coef))],[calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "# print(f\"max accuracy with tuning from {trainable_sequence[max_acc_layer]} layers, or tune {233-trainable_sequence[max_acc_layer]} layers\")\n",
    "print([show_matrix_percentage(my_confusion_matrix)[i,i]*100 for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[...]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 1][:, 0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(\n",
    "    y_true=K.sum(K.cast(K.round(cvscores[1][1][0]), \"int32\"), axis=1).numpy(),\n",
    "    y_pred=K.sum(K.cast(K.round(cvscores[1][1][1]), \"int32\"), axis=1).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.DataFrame(\n",
    "    np.hstack(\n",
    "        np.array(\n",
    "            [\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 0]),\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 1]),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(mycsv[range(4, 8)].to_numpy(), np.vstack(np.array(cvscores)[:, 1][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv.to_csv(\n",
    "    \"./stratified_cross_validation_results/effnet_multinomial.csv\", index=False\n",
    ")\n",
    "# next time include which image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.read_csv(\"./stratified_cross_validation_results/effnet_multinomial.csv\")\n",
    "y_true = np.sum((mycsv[[str(i) for i in range(0, 4)]]).to_numpy(dtype=int), axis=1)\n",
    "y_pred = np.sum(\n",
    "    np.rint((mycsv[[str(i) for i in range(4, 8)]]).to_numpy()), axis=1\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "my_confusion_matrix = confusion_matrix(y_true, y_pred,)\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef\n",
    "np.corrcoef(y_true, np.sum((mycsv[[str(i) for i in range(4, 8)]]).to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc\n",
    "sum(np.isclose(y_true, y_pred)) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, to_file=\"effnet.png\", show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "\n",
    "# Image(filename=\"effnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.sample(frac=1.0)\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    batch_size=56,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    "    #     seed = seed\n",
    ")\n",
    "\n",
    "batch = next(test_set)\n",
    "true_labels = batch[1]\n",
    "predictions = model.predict(batch[0])\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_set, verbose=0))  # loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=80)\n",
    "batch = next(test_set)\n",
    "\n",
    "y_true = batch[1]\n",
    "y_pred = model.predict(batch[0])\n",
    "print(soft_acc_multi_output(y_true, y_pred))\n",
    "\n",
    "# print examples from the validation set\n",
    "for i in range(len(batch[1])):\n",
    "    img = batch[0][i]\n",
    "    label = batch[1][i]\n",
    "    assert (label == y_true[i]).all()\n",
    "    right = K.all(\n",
    "        K.equal(K.cast(K.round(label), \"int32\"), K.cast(K.round(y_pred[i]), \"int32\"),)\n",
    "    )\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(f\"true label: {label}; rounded pred: {y_pred[i]}; Correct: {right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(\n",
    "    str(\"C:/Users/feroc/OneDrive - The University of Melbourne/Dataset/adult/*\")\n",
    ")\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    image_id = tf.strings.split(file_path, os.path.sep)[-1]\n",
    "    return response.loc[] \n",
    "\n",
    "list(list_ds.take(1).as_numpy_iterator())[0]\n",
    "tf.strings.split(list(list_ds.take(1).as_numpy_iterator())[0],os.path.sep)[-1].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
