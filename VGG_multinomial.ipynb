{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.densenet import (\n",
    "    DenseNet121,\n",
    "    preprocess_input,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling2D,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "import efficientnet.tfkeras as enet\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(\n",
    "            len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\",\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def append_extension(fn):\n",
    "    return (fn + \".jpg\").zfill(7)\n",
    "\n",
    "\n",
    "def ordered_logit(class_number):\n",
    "    # zero portability\n",
    "    target = np.zeros(4, dtype=int)\n",
    "    target[: class_number - 2] = 1\n",
    "    return target\n",
    "\n",
    "\n",
    "DATADIR = r\"./adult\"\n",
    "CSV_PATH = r\"./adult/CastControls_ALP.xlsx\"\n",
    "response = pd.read_excel(CSV_PATH, sheet_name=0,)[[\"GreenID\", \"Grade\"]].dropna(\n",
    "    axis=0, subset=[\"Grade\"]\n",
    ")\n",
    "response.Grade = response.Grade.astype(\"int\")\n",
    "response.GreenID = response.GreenID.astype(\"str\").apply(append_extension)\n",
    "response = response[response.Grade != 99]\n",
    "response = pd.concat(\n",
    "    [response, pd.DataFrame.from_dict(dict(response.Grade.apply(ordered_logit))).T,],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle dataset\n",
    "response = response.sample(frac=1)\n",
    "seed = np.random.randint(30027)\n",
    "\n",
    "\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "\n",
    "def soft_acc_multi_output(y_true, y_pred):\n",
    "    return K.mean(\n",
    "        K.all(\n",
    "            K.equal(\n",
    "                K.cast(K.round(y_true), \"int32\"), K.cast(K.round(y_pred), \"int32\"),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(train_index, val_index, test_index):\n",
    "    train_dataset = response.iloc[train_index]\n",
    "    val_dataset = response.iloc[val_index]\n",
    "    test_dataset = response.iloc[test_index]\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True,\n",
    "        rescale=1.0 / 255.0,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "    valid_test_gen = ImageDataGenerator(rescale=1.0 / 255.0,)\n",
    "\n",
    "    train_set = train_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    validation_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=val_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    test_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "innerkf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "response = response.sample(frac=1.0)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "\n",
    "def generate_base_model(fine_tune=None):\n",
    "    i = tf.keras.layers.Input([224, 224, 3], dtype = tf.uint8)\n",
    "    x = tf.cast(i, tf.float32)\n",
    "    x = tf.keras.applications.vgg16.preprocess_input(x)\n",
    "    conv_base = tf.keras.applications.VGG16(\n",
    "    include_top=False, weights='imagenet', input_tensor=None, input_shape=None,\n",
    "    pooling=\"avg\", classes=5,)\n",
    "    conv_base.trainable = True\n",
    "    x = conv_base(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(4, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=i, outputs=preds)\n",
    "                                                     \n",
    "    model.trainable = True\n",
    "#     for layer in model.layers[:fine_tune]:\n",
    "#         layer.trainable = False\n",
    "#     for layer in model.layers[fine_tune:]:\n",
    "#         layer.trainable = True\n",
    "                                                     \n",
    "                                                     \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[soft_acc_multi_output],\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def stratified_cv(fine_tune_layer=None):\n",
    "    acc_coef_scores = []\n",
    "    raw_outputs = []\n",
    "    for train_index, val_test_index in kf.split(\n",
    "        np.zeros(len(response)), response[\"Grade\"]\n",
    "    ):\n",
    "        val_index, test_index = next(\n",
    "            innerkf.split(\n",
    "                np.zeros(len(val_test_index)), response[\"Grade\"].iloc[val_test_index]\n",
    "            )\n",
    "        )\n",
    "        val_index, test_index = val_test_index[val_index], val_test_index[test_index]\n",
    "        train_set, validation_set, test_set = generate_train_val_test(\n",
    "            train_index, val_index, test_index\n",
    "        )\n",
    "        model = generate_base_model()\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=100,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "#             verbose=0,\n",
    "        )\n",
    "\n",
    "        batch = next(test_set)\n",
    "        true_labels = batch[1]\n",
    "        predictions = model.predict(batch[0])\n",
    "        acc = soft_acc_multi_output(predictions, true_labels).numpy()\n",
    "        corr = np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))[0][\n",
    "            1\n",
    "        ]\n",
    "        acc_coef_scores.append([acc, corr])\n",
    "        raw_outputs.append([np.array(response.iloc[test_index].index), true_labels, predictions])\n",
    "        del train_set, validation_set, test_set, _, model, batch, true_labels, predictions, acc, corr\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    return acc_coef_scores, raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 476ms/step - loss: 1.7327 - soft_acc_multi_output: 0.1625 - val_loss: 0.6006 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 1.2058 - soft_acc_multi_output: 0.2167 - val_loss: 1.4912 - val_soft_acc_multi_output: 0.1786\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.7577 - soft_acc_multi_output: 0.2167 - val_loss: 0.6138 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.6750 - soft_acc_multi_output: 0.1813 - val_loss: 0.5776 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.7098 - soft_acc_multi_output: 0.2333 - val_loss: 0.5903 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.7486 - soft_acc_multi_output: 0.2167 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.6024 - soft_acc_multi_output: 0.2292 - val_loss: 0.5894 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.6021 - soft_acc_multi_output: 0.2354 - val_loss: 0.5693 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5831 - soft_acc_multi_output: 0.2583 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5870 - soft_acc_multi_output: 0.3000 - val_loss: 0.5693 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 337ms/step - loss: 0.5861 - soft_acc_multi_output: 0.2646 - val_loss: 0.5688 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5738 - soft_acc_multi_output: 0.2438 - val_loss: 0.5708 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.5752 - soft_acc_multi_output: 0.2250 - val_loss: 0.5698 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5750 - soft_acc_multi_output: 0.2708 - val_loss: 0.5688 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.6023 - soft_acc_multi_output: 0.2375 - val_loss: 0.5728 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5796 - soft_acc_multi_output: 0.2375 - val_loss: 0.5693 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5718 - soft_acc_multi_output: 0.2458 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5687 - soft_acc_multi_output: 0.2750 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 0.5717 - soft_acc_multi_output: 0.2521 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.5726 - soft_acc_multi_output: 0.2521 - val_loss: 0.5708 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5713 - soft_acc_multi_output: 0.2542 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5663 - soft_acc_multi_output: 0.2604 - val_loss: 0.5684 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5732 - soft_acc_multi_output: 0.2625 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5661 - soft_acc_multi_output: 0.2583 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5685 - soft_acc_multi_output: 0.2604 - val_loss: 0.5688 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.5722 - soft_acc_multi_output: 0.2562 - val_loss: 0.5684 - val_soft_acc_multi_output: 0.2679\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5689 - soft_acc_multi_output: 0.2625 - val_loss: 0.5684 - val_soft_acc_multi_output: 0.2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 498ms/step - loss: 2.4879 - soft_acc_multi_output: 0.1625 - val_loss: 1.7373 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 1.4733 - soft_acc_multi_output: 0.1271 - val_loss: 0.6665 - val_soft_acc_multi_output: 0.1754\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 0.6286 - soft_acc_multi_output: 0.2104 - val_loss: 0.5645 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5828 - soft_acc_multi_output: 0.2750 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5736 - soft_acc_multi_output: 0.2396 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5761 - soft_acc_multi_output: 0.2500 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5713 - soft_acc_multi_output: 0.2479 - val_loss: 0.5605 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.5704 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5670 - soft_acc_multi_output: 0.2625 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5607 - soft_acc_multi_output: 0.2625 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 321ms/step - loss: 0.5643 - soft_acc_multi_output: 0.2604 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.5640 - soft_acc_multi_output: 0.2625 - val_loss: 0.5601 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.6131 - soft_acc_multi_output: 0.2292 - val_loss: 0.5718 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.9272 - soft_acc_multi_output: 0.2333 - val_loss: 2.7266 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 305ms/step - loss: 0.8655 - soft_acc_multi_output: 0.2104 - val_loss: 0.5703 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 308ms/step - loss: 0.6186 - soft_acc_multi_output: 0.2729 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5908 - soft_acc_multi_output: 0.2104 - val_loss: 0.5610 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5685 - soft_acc_multi_output: 0.2583 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5700 - soft_acc_multi_output: 0.2604 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 0.5645 - soft_acc_multi_output: 0.2625 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5618 - soft_acc_multi_output: 0.2604 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5550 - soft_acc_multi_output: 0.2604 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5634 - soft_acc_multi_output: 0.2583 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5604 - soft_acc_multi_output: 0.2625 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.5548 - soft_acc_multi_output: 0.2667 - val_loss: 0.5596 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.5555 - soft_acc_multi_output: 0.2604 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 0.5569 - soft_acc_multi_output: 0.2625 - val_loss: 0.5591 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 5s 304ms/step - loss: 0.5602 - soft_acc_multi_output: 0.2604 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 5s 306ms/step - loss: 0.5645 - soft_acc_multi_output: 0.2646 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.5623 - soft_acc_multi_output: 0.2667 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5596 - soft_acc_multi_output: 0.2604 - val_loss: 0.5586 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5578 - soft_acc_multi_output: 0.2625 - val_loss: 0.5581 - val_soft_acc_multi_output: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 462ms/step - loss: 1.8006 - soft_acc_multi_output: 0.1937 - val_loss: 0.6919 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.6902 - soft_acc_multi_output: 0.2937 - val_loss: 0.6885 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.6874 - soft_acc_multi_output: 0.2937 - val_loss: 0.6860 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6845 - soft_acc_multi_output: 0.2937 - val_loss: 0.6831 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.6817 - soft_acc_multi_output: 0.2937 - val_loss: 0.6812 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.6789 - soft_acc_multi_output: 0.2937 - val_loss: 0.6777 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6761 - soft_acc_multi_output: 0.2937 - val_loss: 0.6753 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.6734 - soft_acc_multi_output: 0.2937 - val_loss: 0.6729 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.6709 - soft_acc_multi_output: 0.2937 - val_loss: 0.6699 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 0.6683 - soft_acc_multi_output: 0.2937 - val_loss: 0.6680 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 338ms/step - loss: 0.6657 - soft_acc_multi_output: 0.2937 - val_loss: 0.6655 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.6632 - soft_acc_multi_output: 0.2937 - val_loss: 0.6626 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.6607 - soft_acc_multi_output: 0.2937 - val_loss: 0.6611 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6584 - soft_acc_multi_output: 0.2937 - val_loss: 0.6582 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.6561 - soft_acc_multi_output: 0.2937 - val_loss: 0.6558 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.6538 - soft_acc_multi_output: 0.2937 - val_loss: 0.6548 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.6515 - soft_acc_multi_output: 0.2937 - val_loss: 0.6514 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.6493 - soft_acc_multi_output: 0.2937 - val_loss: 0.6504 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6472 - soft_acc_multi_output: 0.2937 - val_loss: 0.6475 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.6451 - soft_acc_multi_output: 0.2937 - val_loss: 0.6460 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.6430 - soft_acc_multi_output: 0.2937 - val_loss: 0.6440 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.6412 - soft_acc_multi_output: 0.2937 - val_loss: 0.6426 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 5s 330ms/step - loss: 0.6390 - soft_acc_multi_output: 0.2937 - val_loss: 0.6401 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.6372 - soft_acc_multi_output: 0.2937 - val_loss: 0.6387 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.6354 - soft_acc_multi_output: 0.2937 - val_loss: 0.6372 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6336 - soft_acc_multi_output: 0.2937 - val_loss: 0.6348 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.6318 - soft_acc_multi_output: 0.2937 - val_loss: 0.6333 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.6301 - soft_acc_multi_output: 0.2937 - val_loss: 0.6313 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6284 - soft_acc_multi_output: 0.2937 - val_loss: 0.6299 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 5s 347ms/step - loss: 0.6268 - soft_acc_multi_output: 0.2937 - val_loss: 0.6284 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.6252 - soft_acc_multi_output: 0.2937 - val_loss: 0.6270 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6237 - soft_acc_multi_output: 0.2937 - val_loss: 0.6250 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 5s 323ms/step - loss: 0.6221 - soft_acc_multi_output: 0.2937 - val_loss: 0.6240 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.6205 - soft_acc_multi_output: 0.2937 - val_loss: 0.6230 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 5s 323ms/step - loss: 0.6190 - soft_acc_multi_output: 0.2937 - val_loss: 0.6211 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.6178 - soft_acc_multi_output: 0.2937 - val_loss: 0.6201 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.6163 - soft_acc_multi_output: 0.2937 - val_loss: 0.6187 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.6150 - soft_acc_multi_output: 0.2937 - val_loss: 0.6167 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 39/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.6137 - soft_acc_multi_output: 0.2937 - val_loss: 0.6162 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 40/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.6122 - soft_acc_multi_output: 0.2937 - val_loss: 0.6152 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 41/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.6111 - soft_acc_multi_output: 0.2937 - val_loss: 0.6133 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 42/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6099 - soft_acc_multi_output: 0.2937 - val_loss: 0.6123 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 43/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.6086 - soft_acc_multi_output: 0.2937 - val_loss: 0.6113 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 44/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.6075 - soft_acc_multi_output: 0.2937 - val_loss: 0.6104 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 45/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.6064 - soft_acc_multi_output: 0.2937 - val_loss: 0.6089 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 46/100\n",
      "15/15 [==============================] - 5s 340ms/step - loss: 0.6052 - soft_acc_multi_output: 0.2937 - val_loss: 0.6079 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 47/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.6042 - soft_acc_multi_output: 0.2937 - val_loss: 0.6069 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 48/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.6030 - soft_acc_multi_output: 0.2937 - val_loss: 0.6060 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 49/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.6021 - soft_acc_multi_output: 0.2937 - val_loss: 0.6055 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 50/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.6009 - soft_acc_multi_output: 0.2937 - val_loss: 0.6040 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 51/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.5999 - soft_acc_multi_output: 0.2937 - val_loss: 0.6030 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 52/100\n",
      "15/15 [==============================] - 5s 321ms/step - loss: 0.5990 - soft_acc_multi_output: 0.2937 - val_loss: 0.6025 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 53/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5980 - soft_acc_multi_output: 0.2937 - val_loss: 0.6016 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 54/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.5972 - soft_acc_multi_output: 0.2937 - val_loss: 0.6011 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 55/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5962 - soft_acc_multi_output: 0.2937 - val_loss: 0.5996 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 56/100\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.5954 - soft_acc_multi_output: 0.2937 - val_loss: 0.5986 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 57/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.5946 - soft_acc_multi_output: 0.2937 - val_loss: 0.5981 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 58/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.5938 - soft_acc_multi_output: 0.2937 - val_loss: 0.5972 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 59/100\n",
      "15/15 [==============================] - 5s 337ms/step - loss: 0.5928 - soft_acc_multi_output: 0.2937 - val_loss: 0.5967 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 60/100\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 0.5921 - soft_acc_multi_output: 0.2937 - val_loss: 0.5957 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 61/100\n",
      "15/15 [==============================] - 5s 349ms/step - loss: 0.5914 - soft_acc_multi_output: 0.2937 - val_loss: 0.5952 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 62/100\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 0.5906 - soft_acc_multi_output: 0.2937 - val_loss: 0.5942 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 63/100\n",
      "15/15 [==============================] - 5s 329ms/step - loss: 0.5899 - soft_acc_multi_output: 0.2937 - val_loss: 0.5933 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 64/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.5892 - soft_acc_multi_output: 0.2937 - val_loss: 0.5933 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 65/100\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 0.5885 - soft_acc_multi_output: 0.2937 - val_loss: 0.5923 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 66/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5878 - soft_acc_multi_output: 0.2937 - val_loss: 0.5918 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 67/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.5870 - soft_acc_multi_output: 0.2937 - val_loss: 0.5908 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 68/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.5864 - soft_acc_multi_output: 0.2937 - val_loss: 0.5903 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 69/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.5857 - soft_acc_multi_output: 0.2937 - val_loss: 0.5898 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 70/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 0.5852 - soft_acc_multi_output: 0.2937 - val_loss: 0.5889 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 71/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5845 - soft_acc_multi_output: 0.2937 - val_loss: 0.5889 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 72/100\n",
      "15/15 [==============================] - 5s 309ms/step - loss: 0.5839 - soft_acc_multi_output: 0.2937 - val_loss: 0.5879 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 73/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5835 - soft_acc_multi_output: 0.2937 - val_loss: 0.5879 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 74/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.5829 - soft_acc_multi_output: 0.2937 - val_loss: 0.5874 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 75/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5823 - soft_acc_multi_output: 0.2937 - val_loss: 0.5874 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 76/100\n",
      "15/15 [==============================] - 5s 325ms/step - loss: 0.5818 - soft_acc_multi_output: 0.2937 - val_loss: 0.5859 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 77/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.5812 - soft_acc_multi_output: 0.2937 - val_loss: 0.5854 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 78/100\n",
      "15/15 [==============================] - 5s 324ms/step - loss: 0.5807 - soft_acc_multi_output: 0.2937 - val_loss: 0.5854 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 79/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5802 - soft_acc_multi_output: 0.2937 - val_loss: 0.5845 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 80/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.5798 - soft_acc_multi_output: 0.2937 - val_loss: 0.5845 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 81/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.5793 - soft_acc_multi_output: 0.2937 - val_loss: 0.5840 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 82/100\n",
      "15/15 [==============================] - 5s 330ms/step - loss: 0.5788 - soft_acc_multi_output: 0.2937 - val_loss: 0.5835 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 83/100\n",
      "15/15 [==============================] - 5s 339ms/step - loss: 0.5785 - soft_acc_multi_output: 0.2937 - val_loss: 0.5835 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 84/100\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 0.5778 - soft_acc_multi_output: 0.2937 - val_loss: 0.5830 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 85/100\n",
      "15/15 [==============================] - 5s 319ms/step - loss: 0.5775 - soft_acc_multi_output: 0.2937 - val_loss: 0.5820 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 86/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5771 - soft_acc_multi_output: 0.2937 - val_loss: 0.5811 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 87/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.5766 - soft_acc_multi_output: 0.2937 - val_loss: 0.5815 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 88/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5763 - soft_acc_multi_output: 0.2937 - val_loss: 0.5811 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 89/100\n",
      "15/15 [==============================] - 5s 321ms/step - loss: 0.5759 - soft_acc_multi_output: 0.2937 - val_loss: 0.5806 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 90/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5754 - soft_acc_multi_output: 0.2937 - val_loss: 0.5806 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 91/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5752 - soft_acc_multi_output: 0.2937 - val_loss: 0.5801 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 92/100\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 0.5747 - soft_acc_multi_output: 0.2937 - val_loss: 0.5801 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 93/100\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.5745 - soft_acc_multi_output: 0.2937 - val_loss: 0.5796 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 94/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5741 - soft_acc_multi_output: 0.2937 - val_loss: 0.5791 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 95/100\n",
      "15/15 [==============================] - 5s 323ms/step - loss: 0.5738 - soft_acc_multi_output: 0.2937 - val_loss: 0.5791 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 96/100\n",
      "15/15 [==============================] - 5s 329ms/step - loss: 0.5735 - soft_acc_multi_output: 0.2937 - val_loss: 0.5786 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 97/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.5731 - soft_acc_multi_output: 0.2937 - val_loss: 0.5776 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 98/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.5729 - soft_acc_multi_output: 0.2937 - val_loss: 0.5776 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 99/100\n",
      "15/15 [==============================] - 5s 307ms/step - loss: 0.5725 - soft_acc_multi_output: 0.2937 - val_loss: 0.5776 - val_soft_acc_multi_output: 0.2632\n",
      "Epoch 100/100\n",
      "15/15 [==============================] - 5s 326ms/step - loss: 0.5722 - soft_acc_multi_output: 0.2937 - val_loss: 0.5771 - val_soft_acc_multi_output: 0.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 7s 470ms/step - loss: 5.1139 - soft_acc_multi_output: 0.1021 - val_loss: 0.5796 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 354ms/step - loss: 0.6630 - soft_acc_multi_output: 0.1854 - val_loss: 0.6152 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.8907 - soft_acc_multi_output: 0.1813 - val_loss: 0.5762 - val_soft_acc_multi_output: 0.1579\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5734 - soft_acc_multi_output: 0.2208 - val_loss: 0.5679 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 310ms/step - loss: 0.5702 - soft_acc_multi_output: 0.2417 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.5664 - soft_acc_multi_output: 0.2125 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5696 - soft_acc_multi_output: 0.2562 - val_loss: 0.5654 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5671 - soft_acc_multi_output: 0.2500 - val_loss: 0.5654 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.5632 - soft_acc_multi_output: 0.2292 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 1.2079 - soft_acc_multi_output: 0.2479 - val_loss: 0.6367 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 1.7647 - soft_acc_multi_output: 0.1417 - val_loss: 1.5039 - val_soft_acc_multi_output: 0.1579\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 2.1551 - soft_acc_multi_output: 0.1396 - val_loss: 7.5273 - val_soft_acc_multi_output: 0.0000e+00\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 312ms/step - loss: 1.0705 - soft_acc_multi_output: 0.2438 - val_loss: 1.9414 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.7611 - soft_acc_multi_output: 0.2125 - val_loss: 0.6304 - val_soft_acc_multi_output: 0.1579\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.7352 - soft_acc_multi_output: 0.2708 - val_loss: 0.6040 - val_soft_acc_multi_output: 0.1579\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.5845 - soft_acc_multi_output: 0.2875 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 323ms/step - loss: 0.5638 - soft_acc_multi_output: 0.2479 - val_loss: 0.5645 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.5647 - soft_acc_multi_output: 0.2583 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 345ms/step - loss: 0.5583 - soft_acc_multi_output: 0.2646 - val_loss: 0.5645 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 314ms/step - loss: 0.5661 - soft_acc_multi_output: 0.2562 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5618 - soft_acc_multi_output: 0.2438 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.5574 - soft_acc_multi_output: 0.2521 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5606 - soft_acc_multi_output: 0.2521 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5548 - soft_acc_multi_output: 0.2625 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 5s 311ms/step - loss: 0.5566 - soft_acc_multi_output: 0.2562 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 5s 318ms/step - loss: 0.5667 - soft_acc_multi_output: 0.2625 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.5600 - soft_acc_multi_output: 0.2604 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.5656 - soft_acc_multi_output: 0.2500 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 5s 324ms/step - loss: 0.5534 - soft_acc_multi_output: 0.2583 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 30/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.5569 - soft_acc_multi_output: 0.2583 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 31/100\n",
      "15/15 [==============================] - 5s 313ms/step - loss: 0.5567 - soft_acc_multi_output: 0.2521 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 32/100\n",
      "15/15 [==============================] - 5s 317ms/step - loss: 0.5592 - soft_acc_multi_output: 0.2583 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 33/100\n",
      "15/15 [==============================] - 5s 316ms/step - loss: 0.5617 - soft_acc_multi_output: 0.2583 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 34/100\n",
      "15/15 [==============================] - 5s 324ms/step - loss: 0.5536 - soft_acc_multi_output: 0.2562 - val_loss: 0.5669 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 35/100\n",
      "15/15 [==============================] - 5s 315ms/step - loss: 0.5611 - soft_acc_multi_output: 0.2500 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 36/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.5650 - soft_acc_multi_output: 0.2604 - val_loss: 0.5659 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 37/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.5575 - soft_acc_multi_output: 0.2604 - val_loss: 0.5664 - val_soft_acc_multi_output: 0.2807\n",
      "Epoch 38/100\n",
      "15/15 [==============================] - 5s 342ms/step - loss: 0.5583 - soft_acc_multi_output: 0.2562 - val_loss: 0.5674 - val_soft_acc_multi_output: 0.2807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\lib\\function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\feroc\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 453 validated image filenames.\n",
      "Found 53 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 15 steps, validate for 1 steps\n",
      "Epoch 1/100\n",
      "15/15 [==============================] - 8s 551ms/step - loss: 4.5947 - soft_acc_multi_output: 0.1479 - val_loss: 0.6250 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 5s 333ms/step - loss: 0.7614 - soft_acc_multi_output: 0.1396 - val_loss: 0.5850 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 5s 335ms/step - loss: 0.6307 - soft_acc_multi_output: 0.2029 - val_loss: 0.5566 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 5s 333ms/step - loss: 0.6006 - soft_acc_multi_output: 0.2521 - val_loss: 0.5474 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.5987 - soft_acc_multi_output: 0.2446 - val_loss: 0.5493 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 6/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.5811 - soft_acc_multi_output: 0.2646 - val_loss: 0.5449 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 7/100\n",
      "15/15 [==============================] - 5s 336ms/step - loss: 0.5905 - soft_acc_multi_output: 0.2542 - val_loss: 0.5503 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 8/100\n",
      "15/15 [==============================] - 5s 338ms/step - loss: 0.5794 - soft_acc_multi_output: 0.2704 - val_loss: 0.5425 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 9/100\n",
      "15/15 [==============================] - 5s 326ms/step - loss: 0.5873 - soft_acc_multi_output: 0.2333 - val_loss: 0.5479 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 10/100\n",
      "15/15 [==============================] - 5s 338ms/step - loss: 0.5822 - soft_acc_multi_output: 0.2438 - val_loss: 0.5439 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 11/100\n",
      "15/15 [==============================] - 5s 335ms/step - loss: 0.5794 - soft_acc_multi_output: 0.2562 - val_loss: 0.5527 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 12/100\n",
      "15/15 [==============================] - 5s 324ms/step - loss: 0.5826 - soft_acc_multi_output: 0.2583 - val_loss: 0.5532 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 13/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.5799 - soft_acc_multi_output: 0.2500 - val_loss: 0.5444 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 14/100\n",
      "15/15 [==============================] - 5s 327ms/step - loss: 0.5813 - soft_acc_multi_output: 0.2521 - val_loss: 0.5474 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 15/100\n",
      "15/15 [==============================] - 5s 322ms/step - loss: 0.5830 - soft_acc_multi_output: 0.2562 - val_loss: 0.5474 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 16/100\n",
      "15/15 [==============================] - 5s 329ms/step - loss: 0.5770 - soft_acc_multi_output: 0.2604 - val_loss: 0.5479 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 17/100\n",
      "15/15 [==============================] - 5s 330ms/step - loss: 0.5799 - soft_acc_multi_output: 0.2500 - val_loss: 0.5425 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 18/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.5818 - soft_acc_multi_output: 0.2604 - val_loss: 0.5464 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 19/100\n",
      "15/15 [==============================] - 5s 340ms/step - loss: 0.5736 - soft_acc_multi_output: 0.2583 - val_loss: 0.5444 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 20/100\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 0.5744 - soft_acc_multi_output: 0.2612 - val_loss: 0.5464 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 21/100\n",
      "15/15 [==============================] - 5s 320ms/step - loss: 0.5788 - soft_acc_multi_output: 0.2583 - val_loss: 0.5435 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 22/100\n",
      "15/15 [==============================] - 5s 328ms/step - loss: 0.5838 - soft_acc_multi_output: 0.2542 - val_loss: 0.5430 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 23/100\n",
      "15/15 [==============================] - 5s 334ms/step - loss: 0.5753 - soft_acc_multi_output: 0.2604 - val_loss: 0.5469 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 24/100\n",
      "15/15 [==============================] - 5s 324ms/step - loss: 0.5717 - soft_acc_multi_output: 0.2583 - val_loss: 0.5483 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 25/100\n",
      "15/15 [==============================] - 5s 325ms/step - loss: 0.5752 - soft_acc_multi_output: 0.2583 - val_loss: 0.5449 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 26/100\n",
      "15/15 [==============================] - 5s 331ms/step - loss: 0.5806 - soft_acc_multi_output: 0.2604 - val_loss: 0.5454 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 27/100\n",
      "15/15 [==============================] - 5s 334ms/step - loss: 0.5785 - soft_acc_multi_output: 0.2604 - val_loss: 0.5479 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 28/100\n",
      "15/15 [==============================] - 5s 332ms/step - loss: 0.5834 - soft_acc_multi_output: 0.2604 - val_loss: 0.5449 - val_soft_acc_multi_output: 0.3019\n",
      "Epoch 29/100\n",
      "15/15 [==============================] - 5s 329ms/step - loss: 0.5723 - soft_acc_multi_output: 0.2604 - val_loss: 0.5430 - val_soft_acc_multi_output: 0.3019\n"
     ]
    }
   ],
   "source": [
    "acc_coef_scores, raw_outputs = stratified_cv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"./stratified_cross_validation_results/VGGs/multinomial_all\", np.array(raw_outputs).reshape(-1,5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe also include an untuned version for comparison?\n",
    "# np.array([list(response.iloc[np.stack(np.array(raw_outputs)[0,:,0])[i]].index) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_coef = []\n",
    "raw_outputs = []\n",
    "acc_coef.append(acc_coef_scores)\n",
    "raw_outputs.append(raw_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1dc426617deb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mmy_confusion_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_confusion_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"+++++++++++++++++++++++++++++++++\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-1dc426617deb>\u001b[0m in \u001b[0;36mshow_confusion_matrix\u001b[1;34m(raw_outputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     y_pred = np.sum(\n\u001b[0;32m     13\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(len(acc_coef))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def show_confusion_matrix(raw_outputs):\n",
    "\n",
    "    y_true = np.sum(raw_outputs[:, 1], axis=1)\n",
    "    y_pred = np.sum(\n",
    "        np.rint(raw_outputs[:, 2]), axis=1\n",
    "    ).astype(int)\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def show_matrix_percentage(confusion_matrix):\n",
    "    return np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))\n",
    "\n",
    "# total accuracy\n",
    "def calculate_accuracy(my_confusion_matrix):\n",
    "    return np.trace(my_confusion_matrix)/np.sum(my_confusion_matrix)\n",
    "\n",
    "# max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "\n",
    "my_confusion_matrix = show_confusion_matrix(raw_outputs)\n",
    "print(my_confusion_matrix)\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(show_matrix_percentage(my_confusion_matrix))\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(calculate_accuracy(my_confusion_matrix)*100)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(len(acc_coef))],[calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "# print(f\"max accuracy with tuning from {trainable_sequence[max_acc_layer]} layers, or tune {233-trainable_sequence[max_acc_layer]} layers\")\n",
    "print([show_matrix_percentage(my_confusion_matrix)[i,i]*100 for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[...]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_outputs[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 1][:, 0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(\n",
    "    y_true=K.sum(K.cast(K.round(cvscores[1][1][0]), \"int32\"), axis=1).numpy(),\n",
    "    y_pred=K.sum(K.cast(K.round(cvscores[1][1][1]), \"int32\"), axis=1).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.DataFrame(\n",
    "    np.hstack(\n",
    "        np.array(\n",
    "            [\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 0]),\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 1]),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(mycsv[range(4, 8)].to_numpy(), np.vstack(np.array(cvscores)[:, 1][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv.to_csv(\n",
    "    \"./stratified_cross_validation_results/effnet_multinomial.csv\", index=False\n",
    ")\n",
    "# next time include which image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.read_csv(\"./stratified_cross_validation_results/effnet_multinomial.csv\")\n",
    "y_true = np.sum((mycsv[[str(i) for i in range(0, 4)]]).to_numpy(dtype=int), axis=1)\n",
    "y_pred = np.sum(\n",
    "    np.rint((mycsv[[str(i) for i in range(4, 8)]]).to_numpy()), axis=1\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "my_confusion_matrix = confusion_matrix(y_true, y_pred,)\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef\n",
    "np.corrcoef(y_true, np.sum((mycsv[[str(i) for i in range(4, 8)]]).to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc\n",
    "sum(np.isclose(y_true, y_pred)) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, to_file=\"effnet.png\", show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "\n",
    "# Image(filename=\"effnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.sample(frac=1.0)\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    batch_size=56,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    "    #     seed = seed\n",
    ")\n",
    "\n",
    "batch = next(test_set)\n",
    "true_labels = batch[1]\n",
    "predictions = model.predict(batch[0])\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_set, verbose=0))  # loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=80)\n",
    "batch = next(test_set)\n",
    "\n",
    "y_true = batch[1]\n",
    "y_pred = model.predict(batch[0])\n",
    "print(soft_acc_multi_output(y_true, y_pred))\n",
    "\n",
    "# print examples from the validation set\n",
    "for i in range(len(batch[1])):\n",
    "    img = batch[0][i]\n",
    "    label = batch[1][i]\n",
    "    assert (label == y_true[i]).all()\n",
    "    right = K.all(\n",
    "        K.equal(K.cast(K.round(label), \"int32\"), K.cast(K.round(y_pred[i]), \"int32\"),)\n",
    "    )\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(f\"true label: {label}; rounded pred: {y_pred[i]}; Correct: {right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(\n",
    "    str(\"C:/Users/feroc/OneDrive - The University of Melbourne/Dataset/adult/*\")\n",
    ")\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    image_id = tf.strings.split(file_path, os.path.sep)[-1]\n",
    "    return response.loc[] \n",
    "\n",
    "list(list_ds.take(1).as_numpy_iterator())[0]\n",
    "tf.strings.split(list(list_ds.take(1).as_numpy_iterator())[0],os.path.sep)[-1].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
