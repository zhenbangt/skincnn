{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.applications.densenet import (\n",
    "    DenseNet121,\n",
    "    preprocess_input,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import IPython.display as display\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    GlobalMaxPooling2D,\n",
    "    Dropout,\n",
    ")\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    ")\n",
    "import efficientnet.tfkeras as enet\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
    "        print(\n",
    "            len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\",\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def append_extension(fn):\n",
    "    return (fn + \".jpg\").zfill(7)\n",
    "\n",
    "\n",
    "def ordered_logit(class_number):\n",
    "    # zero portability\n",
    "    target = np.zeros(4, dtype=int)\n",
    "    target[: class_number - 2] = 1\n",
    "    return target\n",
    "\n",
    "\n",
    "DATADIR = r\"./adult\"\n",
    "CSV_PATH = r\"./adult/CastControls_ALP.xlsx\"\n",
    "response = pd.read_excel(CSV_PATH, sheet_name=0,)[[\"GreenID\", \"Grade\"]].dropna(\n",
    "    axis=0, subset=[\"Grade\"]\n",
    ")\n",
    "response.Grade = response.Grade.astype(\"int\")\n",
    "response.GreenID = response.GreenID.astype(\"str\").apply(append_extension)\n",
    "response = response[response.Grade != 99]\n",
    "response = pd.concat(\n",
    "    [response, pd.DataFrame.from_dict(dict(response.Grade.apply(ordered_logit))).T,],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# shuffle dataset\n",
    "response = response.sample(frac=1)\n",
    "seed = np.random.randint(30027)\n",
    "\n",
    "\n",
    "def soft_acc(y_true, y_pred):\n",
    "    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))\n",
    "\n",
    "\n",
    "def soft_acc_multi_output(y_true, y_pred):\n",
    "    return K.mean(\n",
    "        K.all(\n",
    "            K.equal(\n",
    "                K.cast(K.round(y_true), \"int32\"), K.cast(K.round(y_pred), \"int32\"),\n",
    "            ),\n",
    "            axis=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = tf.keras.mixed_precision.experimental.Policy(\"mixed_float16\")\n",
    "mixed_precision.experimental.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    fill_mode=\"reflect\",\n",
    "    horizontal_flip=True,\n",
    "    #     vertical_flip=True,\n",
    "    validation_split=0.1,\n",
    "    # dude i wasnt cheating...\n",
    "    rescale=1.0 / 255.0,\n",
    "    #     preprocessing_function = preprocess_input\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "valid_gen = ImageDataGenerator(validation_split=0.1, rescale=1.0 / 255.0,)\n",
    "\n",
    "train_set = train_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    #     class_mode = \"sparse\"\n",
    "    #     y_col=\"Grade\",\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "validation_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    batch_size=28,\n",
    "    #     class_mode = \"sparse\"\n",
    "    #     y_col=\"Grade\",\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "train_set.reset()\n",
    "validation_set.reset()\n",
    "# print(next(validation_set)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "conv_base = enet.EfficientNetB0(\n",
    "    include_top=False, input_shape=(224, 224, 3), pooling=\"avg\", weights=\"imagenet\",\n",
    ")\n",
    "conv_base.trainable = False\n",
    "\n",
    "x = conv_base.output\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(4, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=conv_base.input, outputs=preds)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[soft_acc_multi_output],\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "history_1 = model.fit_generator(\n",
    "    generator=train_set,\n",
    "    epochs=25,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau],\n",
    "    #     verbose=0,\n",
    ")\n",
    "\n",
    "# model.save(\n",
    "#     filepath=\"./saved_models/my_effnet/my_effnet_untuned_1_layer.h5\", save_format=\"h5\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "## fine tuning\n",
    "#########################\n",
    "\n",
    "\n",
    "fine_tune = [layer.name for layer in model.layers].index(r\"top_conv\")\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:fine_tune]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[fine_tune:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "print(\n",
    "    f\"from {fine_tune} of {len(model.layers)} layers; {len(model.trainable_variables)} trainables variables\"\n",
    ")\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[soft_acc_multi_output],\n",
    ")\n",
    "train_set.reset()\n",
    "validation_set.reset()\n",
    "\n",
    "\n",
    "# logdir_name = (\n",
    "#     r\".\\tfb\\logs\\effnet\\\\\"\n",
    "#     + \"effnet__1_layer\"\n",
    "#     + \"__\"\n",
    "#     + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# )\n",
    "# tensorboard_callback = TensorBoard(log_dir=logdir_name)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "# initial epoch is useless for keras optimizers as they update internally independent of epoch number\n",
    "history_fine = model.fit_generator(\n",
    "    generator=train_set,\n",
    "    epochs=100,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau,],\n",
    ")\n",
    "\n",
    "# model.save(\n",
    "#     filepath=\"./saved_models/my_effnet/tuned_1_layer.h5\", save_format=\"h5\",\n",
    "# )\n",
    "# model.save_weights(\n",
    "#     \"./saved_models/my_effnet/tuned_1_layer_weights_only.h5\", save_format=\"h5\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "\n",
    "# model__ = tf.keras.models.load_model(\n",
    "#     \"./saved_models/my_effnet/tuned_1_layer.h5\",\n",
    "#     custom_objects={\"soft_acc_multi_output\": soft_acc_multi_output},\n",
    "# )\n",
    "\n",
    "# model__.trainable = False\n",
    "# len(model__.trainable_variables)\n",
    "# model__.compile(\n",
    "#         optimizer=keras.optimizers.Nadam(learning_rate=0.0001),\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         metrics=[soft_acc_multi_output],\n",
    "#     )\n",
    "\n",
    "model__ = generate_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "traintest = list(kf.split(np.zeros(len(response)), response[\"Grade\"]))\n",
    "train_index, test_index = np.stack(traintest)[:, 0][0], np.stack(traintest)[:, 1][0]\n",
    "\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=5,\n",
    "    fill_mode=\"reflect\",\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0,\n",
    "    rescale=1.0 / 255.0,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "valid_gen = ImageDataGenerator(validation_split=0.5, rescale=1.0 / 255.0,)\n",
    "\n",
    "train_set = train_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[train_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=False,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "validation_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[test_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"training\",\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response.iloc[test_index],\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=True,\n",
    "    batch_size=64,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model__ = fine_tune_model(model__,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# batch = next(test_set)\n",
    "# true_labels = batch[1]\n",
    "# predictions = model__.predict(batch[0])\n",
    "\n",
    "# print(model__.metrics_names)\n",
    "# print(\n",
    "#     model__.evaluate(train_set, verbose=0)\n",
    "# )  # working well with original unstratified model, including both trainning and testing sets?\n",
    "\n",
    "model__.fit(\n",
    "    x=train_set,\n",
    "    epochs=10,\n",
    "    validation_data=validation_set,\n",
    "    callbacks=[early_stopping, reduce_lr_plateau],\n",
    "    #         verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_val_test(train_index, val_index, test_index):\n",
    "    train_dataset = response.iloc[train_index]\n",
    "    val_dataset = response.iloc[val_index]\n",
    "    test_dataset = response.iloc[test_index]\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rotation_range=5,\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True,\n",
    "        rescale=1.0 / 255.0,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "    valid_test_gen = ImageDataGenerator(rescale=1.0 / 255.0,)\n",
    "\n",
    "    train_set = train_gen.flow_from_dataframe(\n",
    "        dataframe=train_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=True,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    validation_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=val_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "\n",
    "    test_set = valid_test_gen.flow_from_dataframe(\n",
    "        dataframe=test_dataset,\n",
    "        directory=DATADIR,\n",
    "        x_col=\"GreenID\",\n",
    "        target_size=(224, 224),\n",
    "        color_mode=\"rgb\",\n",
    "        subset=\"training\",\n",
    "        shuffle=False,\n",
    "        batch_size=64,\n",
    "        y_col=[0, 1, 2, 3,],\n",
    "        class_mode=\"raw\",\n",
    "    )\n",
    "    return train_set, validation_set, test_set\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "innerkf = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "response = response.sample(frac=1.0)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=21, restore_best_weights=True,\n",
    ")\n",
    "reduce_lr_plateau = ReduceLROnPlateau(monitor=\"val_loss\", patience=7, factor=0.8)\n",
    "\n",
    "\n",
    "def generate_base_model():\n",
    "    conv_base = enet.EfficientNetB0(\n",
    "        include_top=False, input_shape=(224, 224, 3), pooling=\"avg\", weights=\"imagenet\",\n",
    "    )\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    x = conv_base.output\n",
    "    x = Dropout(0.5)(x)\n",
    "    preds = Dense(4, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=conv_base.input, outputs=preds)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(lr=0.0014),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[soft_acc_multi_output],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def fine_tune_model(model, fine_tune=None):\n",
    "    if fine_tune is None:\n",
    "        try:\n",
    "            fine_tune = [layer.name for layer in model.layers].index(r\"top_conv\")\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    model.trainable = True\n",
    "    for layer in model.layers[:fine_tune]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[fine_tune:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Nadam(lr=0.0003),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[soft_acc_multi_output],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def stratified_cv(fine_tune_layer=None):\n",
    "    acc_coef_scores = []\n",
    "    raw_outputs = []\n",
    "    for train_index, val_test_index in kf.split(\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        np.zeros(len(response)), response[\"Grade\"]\n",
    "    ):\n",
    "        val_index, test_index = next(\n",
    "            innerkf.split(\n",
    "                np.zeros(len(val_test_index)), response[\"Grade\"].iloc[val_test_index]\n",
    "            )\n",
    "        )\n",
    "        val_index, test_index = val_test_index[val_index], val_test_index[test_index]\n",
    "        train_set, validation_set, test_set = generate_train_val_test(\n",
    "            train_index, val_index, test_index\n",
    "        )\n",
    "        model = generate_base_model()\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=15,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        model = fine_tune_model(model, fine_tune=fine_tune_layer)\n",
    "\n",
    "        _ = model.fit(\n",
    "            x=train_set,\n",
    "            epochs=100,\n",
    "            validation_data=validation_set,\n",
    "            callbacks=[early_stopping, reduce_lr_plateau],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        batch = next(test_set)\n",
    "        true_labels = batch[1]\n",
    "        predictions = model.predict(batch[0])\n",
    "        acc = soft_acc_multi_output(predictions, true_labels).numpy()\n",
    "        corr = np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))[0][\n",
    "            1\n",
    "        ]\n",
    "        acc_coef_scores.append([acc, corr])\n",
    "        raw_outputs.append([np.array(response.iloc[test_index].index), true_labels, predictions])\n",
    "        del train_set, validation_set, test_set, _, model, batch, true_labels, predictions, acc, corr\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "    return acc_coef_scores, raw_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 3 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 55 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 6 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 449 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 5 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 1 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 validated image filenames.\n",
      "Found 56 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 4 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n",
      "C:\\Users\\ferocs\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"GreenID\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 452 validated image filenames.\n",
      "Found 54 validated image filenames.\n",
      "Found 57 validated image filenames.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    }
   ],
   "source": [
    "#  np.where(np.array(['conv' in layer.name for layer in model.layers]) == True)[0][::-1]\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "\n",
    "\n",
    "fine_tune_scores_acc_coef = []\n",
    "fine_tune_raw_outputs = []\n",
    "\n",
    "for fine_tune in trainable_sequence[12:20]:\n",
    "    acc_coef_scores, raw_outputs = stratified_cv(fine_tune)\n",
    "    fine_tune_scores_acc_coef.append(acc_coef_scores)\n",
    "    fine_tune_raw_outputs.append(raw_outputs)\n",
    "    np.save(r\"./stratified_cross_validation_results/effnets/multinomial_acc_coef_12-20\", np.array(fine_tune_scores_acc_coef))\n",
    "    np.save(r\"./stratified_cross_validation_results/effnets/multinomial_raw_outputs_12-20\", np.array(fine_tune_raw_outputs))\n",
    "    del acc_coef_scores, raw_outputs\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe also include an untuned version for comparison?\n",
    "# np.array([list(response.iloc[np.stack(np.array(raw_outputs)[0,:,0])[i]].index) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[31  9  4  1  0]\n",
      " [10 29 11  5  0]\n",
      " [ 7 18 41 10  3]\n",
      " [ 0  8 13 15 13]\n",
      " [ 0  0 11 12 32]]\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "[[0.68888889 0.2        0.08888889 0.02222222 0.        ]\n",
      " [0.18181818 0.52727273 0.2        0.09090909 0.        ]\n",
      " [0.08860759 0.2278481  0.51898734 0.12658228 0.03797468]\n",
      " [0.         0.16326531 0.26530612 0.30612245 0.26530612]\n",
      " [0.         0.         0.2        0.21818182 0.58181818]]\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "0.5229681978798587\n",
      "+++++++++++++++++++++++++++++++++\n",
      "+++++++++++++++++++++++++++++++++\n",
      "max accuracy with tuning from 225 layers, or tune 8 layers\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "acc_coef = np.load(r\"./stratified_cross_validation_results/effnets/multinomial_acc_coef_12-20.npy\", allow_pickle=True)\n",
    "raw_outputs = np.load(r\"./stratified_cross_validation_results/effnets/multinomial_raw_outputs_12-20.npy\", allow_pickle=True)\n",
    "print(len(acc_coef))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def show_confusion_matrix(raw_outputs, fine_tune_layers):\n",
    "\n",
    "    y_true = np.sum(np.vstack(raw_outputs[fine_tune_layers, :, 1]), axis=1)\n",
    "    y_pred = np.sum(\n",
    "        np.rint(np.vstack(raw_outputs[fine_tune_layers, :, 2])), axis=1\n",
    "    ).astype(int)\n",
    "    return confusion_matrix(y_true, y_pred)\n",
    "\n",
    "def show_matrix_percentage(confusion_matrix):\n",
    "    return np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))\n",
    "\n",
    "# total accuracy\n",
    "def calculate_accuracy(my_confusion_matrix):\n",
    "    return np.trace(my_confusion_matrix)/np.sum(my_confusion_matrix)\n",
    "\n",
    "max_acc_layer = np.argmax([calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "\n",
    "my_confusion_matrix = show_confusion_matrix(raw_outputs,max_acc_layer)\n",
    "print(my_confusion_matrix)\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(show_matrix_percentage(my_confusion_matrix))\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(calculate_accuracy(my_confusion_matrix))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(len(acc_coef))],[calculate_accuracy(show_confusion_matrix(raw_outputs, i))  for i in range(len(acc_coef))])\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "print(\"+++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "trainable_sequence = np.array([227, 225, 217, 214, 210, 202, 199, 195, 187, 184, 180, 172, 169,\n",
    "       167, 159, 156, 152, 144, 141, 137, 129, 126, 124, 116, 113, 109,\n",
    "       101,  98,  94,  86,  83,  81,  73,  70,  66,  58,  55,  53,  45,\n",
    "        42,  38,  30,  27,  25,  17,  14,  12,   4,   1])\n",
    "print(f\"max accuracy with tuning from {trainable_sequence[max_acc_layer]} layers, or tune {233-trainable_sequence[max_acc_layer]} layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 1][:, 0][4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(cvscores)[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(\n",
    "    y_true=K.sum(K.cast(K.round(cvscores[1][1][0]), \"int32\"), axis=1).numpy(),\n",
    "    y_pred=K.sum(K.cast(K.round(cvscores[1][1][1]), \"int32\"), axis=1).numpy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.DataFrame(\n",
    "    np.hstack(\n",
    "        np.array(\n",
    "            [\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 0]),\n",
    "                np.vstack(np.array(cvscores)[:, 1][:, 1]),\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(mycsv[range(4, 8)].to_numpy(), np.vstack(np.array(cvscores)[:, 1][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv.to_csv(\n",
    "    \"./stratified_cross_validation_results/effnet_multinomial.csv\", index=False\n",
    ")\n",
    "# next time include which image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycsv = pd.read_csv(\"./stratified_cross_validation_results/effnet_multinomial.csv\")\n",
    "y_true = np.sum((mycsv[[str(i) for i in range(0, 4)]]).to_numpy(dtype=int), axis=1)\n",
    "y_pred = np.sum(\n",
    "    np.rint((mycsv[[str(i) for i in range(4, 8)]]).to_numpy()), axis=1\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "my_confusion_matrix = confusion_matrix(y_true, y_pred,)\n",
    "my_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.transpose(np.transpose(my_confusion_matrix) / np.sum(my_confusion_matrix, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coef\n",
    "np.corrcoef(y_true, np.sum((mycsv[[str(i) for i in range(4, 8)]]).to_numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc\n",
    "sum(np.isclose(y_true, y_pred)) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot_model(model, to_file=\"effnet.png\", show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "\n",
    "# Image(filename=\"effnet.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response.sample(frac=1.0)\n",
    "\n",
    "test_set = valid_gen.flow_from_dataframe(\n",
    "    dataframe=response,\n",
    "    directory=DATADIR,\n",
    "    x_col=\"GreenID\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    subset=\"validation\",\n",
    "    shuffle=False,\n",
    "    batch_size=56,\n",
    "    y_col=[0, 1, 2, 3,],\n",
    "    class_mode=\"raw\",\n",
    "    #     seed = seed\n",
    ")\n",
    "\n",
    "batch = next(test_set)\n",
    "true_labels = batch[1]\n",
    "predictions = model.predict(batch[0])\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate(test_set, verbose=0))  # loss/accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(np.sum(predictions, axis=1), np.sum(true_labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=80)\n",
    "batch = next(test_set)\n",
    "\n",
    "y_true = batch[1]\n",
    "y_pred = model.predict(batch[0])\n",
    "print(soft_acc_multi_output(y_true, y_pred))\n",
    "\n",
    "# print examples from the validation set\n",
    "for i in range(len(batch[1])):\n",
    "    img = batch[0][i]\n",
    "    label = batch[1][i]\n",
    "    assert (label == y_true[i]).all()\n",
    "    right = K.all(\n",
    "        K.equal(K.cast(K.round(label), \"int32\"), K.cast(K.round(y_pred[i]), \"int32\"),)\n",
    "    )\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(f\"true label: {label}; rounded pred: {y_pred[i]}; Correct: {right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(\n",
    "    str(\"C:/Users/feroc/OneDrive - The University of Melbourne/Dataset/adult/*\")\n",
    ")\n",
    "\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    image_id = tf.strings.split(file_path, os.path.sep)[-1]\n",
    "    return response.loc[] \n",
    "\n",
    "list(list_ds.take(1).as_numpy_iterator())[0]\n",
    "tf.strings.split(list(list_ds.take(1).as_numpy_iterator())[0],os.path.sep)[-1].numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
