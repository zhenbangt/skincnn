{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T14:17:13.037545Z",
     "start_time": "2020-02-02T14:17:12.646086Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# the directory with all data\n",
    "DATADIR = r\".\\adult\" \n",
    "RESPONSEDIR = r\".\\adult\\CastControls_ALP.xlsx\"\n",
    "\n",
    "\n",
    "# IMGWIDTH,IMGHEIGHT = (52, 70)\n",
    "# IMGWIDTH,IMGHEIGHT = (130, 174)\n",
    "# IMGWIDTH,IMGHEIGHT = (260, 348)\n",
    "IMGWIDTH,IMGHEIGHT = (520, 696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:28.903675Z",
     "start_time": "2020-01-20T11:09:28.861787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# explaination\n",
    "# pd.read_excel(io=RESPONSEDIR, sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T14:17:48.478200Z",
     "start_time": "2020-02-02T14:17:46.767119Z"
    }
   },
   "outputs": [],
   "source": [
    "response = pd.read_excel(io=RESPONSEDIR, sheet_name=0)\n",
    "response = response.dropna(axis=0, subset=['Grade'])\n",
    "response.Grade = response.Grade.astype(int)\n",
    "\n",
    "import cv2\n",
    "df = pd.DataFrame(columns=['GreenID','img_array'],dtype='int64')\n",
    "for image in os.listdir(DATADIR):\n",
    "    if 'jpg' in image:\n",
    "        img_array = cv2.imread(os.path.join(DATADIR, image), cv2.IMREAD_GRAYSCALE)\n",
    "        # noticed they all have shape (520, 696)\n",
    "        # problly resize if out of memory\n",
    "    #     img_array = cv2.resize(img_array, (IMGHEIGHT, IMGWIDTH))\n",
    "        df = df.append({'GreenID':int(re.search('[0-9]+', image).group(0)), 'img_array':img_array},ignore_index=True)\n",
    "\n",
    "train = df.merge(response, how='inner', on='GreenID')\n",
    "# want to remove either missing image or missing grade record\n",
    "\n",
    "# filter out 'ungradables', and also the the poor quality ones (add them back later, maybe)\n",
    "train_filter = train[~((train.Grade >= 6.01) | (train.Grade <= 0.99) )].sample(frac=1).reset_index()[['img_array', 'Grade','GreenID']]\n",
    "# train_filter.img_array = train_filter['img_array'].apply(lambda x: np.array(x.flatten()))\n",
    "# train_filter.img_array = train_filter.img_array.apply(lambda x: x.reshape(IMGWIDTH,IMGHEIGHT,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-02T14:17:50.436421Z",
     "start_time": "2020-02-02T14:17:50.433430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "train_filter['img_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see if can be reconstructed (we want to convert to 1d array and normalise within each array)\n",
    "# train_filter['img_array'].apply(lambda x: x.flatten().reshape(IMGWIDTH, IMGHEIGHT))[0]\n",
    "fig, ax = plt.subplots(dpi=160)\n",
    "plt.imshow(train_filter['img_array'].apply(lambda x: x.flatten().reshape(IMGWIDTH, IMGHEIGHT))[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filter[['img_array', 'Grade','GreenID']].to_pickle(r'.\\processed_data\\raw_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some croppping then\n",
    "import cv2 \n",
    "df.img_array = df.img_array.apply(lambda x: x.reshape(IMGWIDTH,IMGHEIGHT, 1))\n",
    "\n",
    "croped = pd.Series(list(np.array([tf.image.random_crop(\n",
    "    df.img_array, (len(df.img_array), RE_SIZE, RE_SIZE ,1)).numpy() for i in range(40)]).reshape(-1, 250, 250, 1)))\n",
    "\n",
    "grades = pd.Series(np.array([df.Grade.values for i in range(40)]).reshape(-1))\n",
    "crop_df = pd.concat([croped,grades],axis=1)\n",
    "# crop_df.to_pickle(r\".\\processed_data\\cropped_data.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "DATADIR = r\".\\adult\"\n",
    "RESPONSEDIR = r\".\\CastControls_ALP.xlsx\"\n",
    "\n",
    "\n",
    "# IMGWIDTH,IMGHEIGHT = (52, 70)\n",
    "# IMGWIDTH,IMGHEIGHT = (130, 174)\n",
    "# IMGWIDTH,IMGHEIGHT = (260, 348)\n",
    "IMGWIDTH,IMGHEIGHT = (520, 696)\n",
    "\n",
    "\n",
    "train_filter = pd.read_pickle(r'.\\processed_data\\raw_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_imgs = tf.image.random_crop(value=np.stack(train_filter.head(5).img_array.values), size = (5,250,250,1)).numpy().reshape(-1,250,250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=160)\n",
    "plt.imshow(cropped_imgs[0] ,cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tf.image.random_crop(value=np.stack(train_filter.head(5).img_array.values), size = (5,250,250,1)).numpy() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:40.562680Z",
     "start_time": "2020-01-20T11:09:40.559692Z"
    }
   },
   "outputs": [],
   "source": [
    "# train[train.duplicated('ControlID', keep=False)].sort_values('ControlID',kind='mergesort')\n",
    "# how to treat duplicated controlID? (correlation between inputs) maby be give less weight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now decide weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:42.550270Z",
     "start_time": "2020-01-20T11:09:42.548275Z"
    }
   },
   "outputs": [],
   "source": [
    "# if differ, treat as 2 cases but half weight; if same, double the weight\n",
    "# maybe give less weight to the poor qualities\n",
    "# does left or right matter?\n",
    "# train_filter[~train_filter.RepeatGrade.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:44.699590Z",
     "start_time": "2020-01-20T11:09:44.541014Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.array(np.stack(train_filter.img_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "img = np.random.randint(np.random.randint(563))\n",
    "fig, ax = plt.subplots(dpi=160)\n",
    "plt.imshow(X[img],cmap='gray')\n",
    "plt.show()\n",
    "print('GreenID: {} ; Rating: {}; Comments: {}'.format(train_filter.GreenID[img], train_filter.Grade[img], train_filter.CastStatusComments[img]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:48.758824Z",
     "start_time": "2020-01-20T11:09:48.646264Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[2].reshape(-1,IMGWIDTH,IMGHEIGHT)[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T11:09:51.322243Z",
     "start_time": "2020-01-20T11:09:50.746266Z"
    }
   },
   "outputs": [],
   "source": [
    "PROCESSEDDIR = r\".\\processed_data\"\n",
    "\n",
    "# do not standardise/ohe yet\n",
    "X_train = X.reshape(-1,IMGWIDTH,IMGHEIGHT,1)\n",
    "y_train = train_filter.Grade.values\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# ohe = OneHotEncoder(handle_unknown='ignore',sparse=False, dtype=np.int)\n",
    "# y_train = ohe.fit_transform(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is found out that fitting the entire image into the model is very inefficient; simply downscaling would also be very bad since the sample size is already extremely small. Maybe try random cropping first?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1094.86px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
